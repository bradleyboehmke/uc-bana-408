<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Lesson 2a: Simple linear regression | Data Mining with R</title>
  <meta name="description" content="Master the art of data wrangling &amp; analysis with the R programming language." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Lesson 2a: Simple linear regression | Data Mining with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Master the art of data wrangling &amp; analysis with the R programming language." />
  <meta name="github-repo" content="bradleyboehmke/uc-bana-7025" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Lesson 2a: Simple linear regression | Data Mining with R" />
  <meta name="twitter:site" content="@bradleyboehmke" />
  <meta name="twitter:description" content="Master the art of data wrangling &amp; analysis with the R programming language." />
  

<meta name="author" content="Bradley Boehmke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="overview-1.html"/>
<link rel="next" href="lesson-2b-multiple-linear-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.9/grViz.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">UC BANA 4080: Data Mining</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Syllabus</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-objectives"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#material"><i class="fa fa-check"></i>Material</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#class-structure"><i class="fa fa-check"></i>Class Structure</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#schedule"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#conventions-used-in-this-book"><i class="fa fa-check"></i>Conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#feedback"><i class="fa fa-check"></i>Feedback</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="part"><span><b>I Module 1</b></span></li>
<li class="chapter" data-level="1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1</b> Overview</a>
<ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html#learning-objectives-1"><i class="fa fa-check"></i><b>1.1</b> Learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="overview.html"><a href="overview.html#estimated-time-requirement"><i class="fa fa-check"></i><b>1.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="1.3" data-path="overview.html"><a href="overview.html#tasks"><i class="fa fa-check"></i><b>1.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html"><i class="fa fa-check"></i><b>2</b> Lesson 1a: Intro to machine learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#learning-objectives-2"><i class="fa fa-check"></i><b>2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>2.2</b> Supervised learning</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#regression-problems"><i class="fa fa-check"></i><b>2.2.1</b> Regression problems</a></li>
<li class="chapter" data-level="2.2.2" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#classification-problems"><i class="fa fa-check"></i><b>2.2.2</b> Classification problems</a></li>
<li class="chapter" data-level="2.2.3" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#knowledge-check"><i class="fa fa-check"></i><b>2.2.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.3</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#knowledge-check-1"><i class="fa fa-check"></i><b>2.3.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#machine-learning-in"><i class="fa fa-check"></i><b>2.4</b> Machine Learning in <svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#knowledge-check-2"><i class="fa fa-check"></i><b>2.4.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#the-data-sets"><i class="fa fa-check"></i><b>2.5</b> The data sets</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#boston-housing"><i class="fa fa-check"></i><b>2.5.1</b> Boston housing</a></li>
<li class="chapter" data-level="2.5.2" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#pima-indians-diabetes"><i class="fa fa-check"></i><b>2.5.2</b> Pima Indians Diabetes</a></li>
<li class="chapter" data-level="2.5.3" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#iris-flowers"><i class="fa fa-check"></i><b>2.5.3</b> Iris flowers</a></li>
<li class="chapter" data-level="2.5.4" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#ames-housing"><i class="fa fa-check"></i><b>2.5.4</b> Ames housing</a></li>
<li class="chapter" data-level="2.5.5" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#attrition"><i class="fa fa-check"></i><b>2.5.5</b> Attrition</a></li>
<li class="chapter" data-level="2.5.6" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#hitters"><i class="fa fa-check"></i><b>2.5.6</b> Hitters</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#what-youll-learn-next"><i class="fa fa-check"></i><b>2.6</b> What You’ll Learn Next</a></li>
<li class="chapter" data-level="2.7" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#exercises"><i class="fa fa-check"></i><b>2.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html"><i class="fa fa-check"></i><b>3</b> Lesson 1b: First model with Tidymodels</a>
<ul>
<li class="chapter" data-level="3.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#learning-objectives-3"><i class="fa fa-check"></i><b>3.1</b> Learning objectives</a></li>
<li class="chapter" data-level="3.2" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#prerequisites"><i class="fa fa-check"></i><b>3.2</b> Prerequisites</a></li>
<li class="chapter" data-level="3.3" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#data-splitting"><i class="fa fa-check"></i><b>3.3</b> Data splitting</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#simple-random-sampling"><i class="fa fa-check"></i><b>3.3.1</b> Simple random sampling</a></li>
<li class="chapter" data-level="3.3.2" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#stratified-sampling"><i class="fa fa-check"></i><b>3.3.2</b> Stratified sampling</a></li>
<li class="chapter" data-level="3.3.3" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#knowledge-check-3"><i class="fa fa-check"></i><b>3.3.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#building-models"><i class="fa fa-check"></i><b>3.4</b> Building models</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#knowledge-check-4"><i class="fa fa-check"></i><b>3.4.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#making-predictions"><i class="fa fa-check"></i><b>3.5</b> Making predictions</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#knowledge-check-5"><i class="fa fa-check"></i><b>3.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#evaluating-model-performance"><i class="fa fa-check"></i><b>3.6</b> Evaluating model performance</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#regression-models"><i class="fa fa-check"></i><b>3.6.1</b> Regression models</a></li>
<li class="chapter" data-level="3.6.2" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#classification-models"><i class="fa fa-check"></i><b>3.6.2</b> Classification models</a></li>
<li class="chapter" data-level="3.6.3" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#knowledge-check-6"><i class="fa fa-check"></i><b>3.6.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#exercises-1"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Module 2</b></span></li>
<li class="chapter" data-level="4" data-path="overview-1.html"><a href="overview-1.html"><i class="fa fa-check"></i><b>4</b> Overview</a>
<ul>
<li class="chapter" data-level="4.1" data-path="overview-1.html"><a href="overview-1.html#learning-objectives-4"><i class="fa fa-check"></i><b>4.1</b> Learning objectives</a></li>
<li class="chapter" data-level="4.2" data-path="overview-1.html"><a href="overview-1.html#estimated-time-requirement-1"><i class="fa fa-check"></i><b>4.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="4.3" data-path="overview-1.html"><a href="overview-1.html#tasks-1"><i class="fa fa-check"></i><b>4.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html"><i class="fa fa-check"></i><b>5</b> Lesson 2a: Simple linear regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#learning-objectives-5"><i class="fa fa-check"></i><b>5.1</b> Learning objectives</a></li>
<li class="chapter" data-level="5.2" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#prerequisites-1"><i class="fa fa-check"></i><b>5.2</b> Prerequisites</a></li>
<li class="chapter" data-level="5.3" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#correlation"><i class="fa fa-check"></i><b>5.3</b> Correlation</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#knowledge-check-7"><i class="fa fa-check"></i><b>5.3.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>5.4</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#best-fit-line"><i class="fa fa-check"></i><b>5.4.1</b> Best fit line</a></li>
<li class="chapter" data-level="5.4.2" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#estimating-best-fit"><i class="fa fa-check"></i><b>5.4.2</b> Estimating “best fit”</a></li>
<li class="chapter" data-level="5.4.3" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#inference"><i class="fa fa-check"></i><b>5.4.3</b> Inference</a></li>
<li class="chapter" data-level="5.4.4" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#knowledge-check-8"><i class="fa fa-check"></i><b>5.4.4</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#making-predictions-1"><i class="fa fa-check"></i><b>5.5</b> Making predictions</a></li>
<li class="chapter" data-level="5.6" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#assessing-model-accuracy"><i class="fa fa-check"></i><b>5.6</b> Assessing model accuracy</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#training-data-accuracy"><i class="fa fa-check"></i><b>5.6.1</b> Training data accuracy</a></li>
<li class="chapter" data-level="5.6.2" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#test-data-accuracy"><i class="fa fa-check"></i><b>5.6.2</b> Test data accuracy</a></li>
<li class="chapter" data-level="5.6.3" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#knowledge-check-9"><i class="fa fa-check"></i><b>5.6.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#exercises-2"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
<li class="chapter" data-level="5.8" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#other-resources"><i class="fa fa-check"></i><b>5.8</b> Other resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Lesson 2b: Multiple linear regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#learning-objectives-6"><i class="fa fa-check"></i><b>6.1</b> Learning objectives</a></li>
<li class="chapter" data-level="6.2" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#prerequisites-2"><i class="fa fa-check"></i><b>6.2</b> Prerequisites</a></li>
<li class="chapter" data-level="6.3" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#adding-additional-predictors"><i class="fa fa-check"></i><b>6.3</b> Adding additional predictors</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#knowledge-check-10"><i class="fa fa-check"></i><b>6.3.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#interactions"><i class="fa fa-check"></i><b>6.4</b> Interactions</a></li>
<li class="chapter" data-level="6.5" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#qualitative-predictors"><i class="fa fa-check"></i><b>6.5</b> Qualitative predictors</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#knowledge-check-11"><i class="fa fa-check"></i><b>6.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#including-many-predictors"><i class="fa fa-check"></i><b>6.6</b> Including many predictors</a></li>
<li class="chapter" data-level="6.7" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#feature-importance"><i class="fa fa-check"></i><b>6.7</b> Feature importance</a></li>
<li class="chapter" data-level="6.8" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#exercises-3"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>III Module 3</b></span></li>
<li class="chapter" data-level="7" data-path="overview-2.html"><a href="overview-2.html"><i class="fa fa-check"></i><b>7</b> Overview</a>
<ul>
<li class="chapter" data-level="7.1" data-path="overview-2.html"><a href="overview-2.html#learning-objectives-7"><i class="fa fa-check"></i><b>7.1</b> Learning objectives</a></li>
<li class="chapter" data-level="7.2" data-path="overview-2.html"><a href="overview-2.html#estimated-time-requirement-2"><i class="fa fa-check"></i><b>7.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="7.3" data-path="overview-2.html"><a href="overview-2.html#tasks-2"><i class="fa fa-check"></i><b>7.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html"><i class="fa fa-check"></i><b>8</b> Lesson 3a: Feature engineering</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#learning-objectives-8"><i class="fa fa-check"></i><b>8.1</b> Learning objectives</a></li>
<li class="chapter" data-level="8.2" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#prerequisites-3"><i class="fa fa-check"></i><b>8.2</b> Prerequisites</a></li>
<li class="chapter" data-level="8.3" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#create-a-recipe"><i class="fa fa-check"></i><b>8.3</b> Create a recipe</a></li>
<li class="chapter" data-level="8.4" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#numeric-features"><i class="fa fa-check"></i><b>8.4</b> Numeric features</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#standardizing"><i class="fa fa-check"></i><b>8.4.1</b> Standardizing</a></li>
<li class="chapter" data-level="8.4.2" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#normalizing"><i class="fa fa-check"></i><b>8.4.2</b> Normalizing</a></li>
<li class="chapter" data-level="8.4.3" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#knowledge-check-12"><i class="fa fa-check"></i><b>8.4.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#categorical-features"><i class="fa fa-check"></i><b>8.5</b> Categorical features</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#one-hot-dummy-encoding"><i class="fa fa-check"></i><b>8.5.1</b> One-hot &amp; dummy encoding</a></li>
<li class="chapter" data-level="8.5.2" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#ordinal-encoding"><i class="fa fa-check"></i><b>8.5.2</b> Ordinal encoding</a></li>
<li class="chapter" data-level="8.5.3" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#lumping"><i class="fa fa-check"></i><b>8.5.3</b> Lumping</a></li>
<li class="chapter" data-level="8.5.4" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#knowledge-check-13"><i class="fa fa-check"></i><b>8.5.4</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#fit-a-model-with-a-recipe"><i class="fa fa-check"></i><b>8.6</b> Fit a model with a recipe</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#knowledge-check-14"><i class="fa fa-check"></i><b>8.6.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#exercises-4"><i class="fa fa-check"></i><b>8.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html"><i class="fa fa-check"></i><b>9</b> Lesson 3b: Resampling</a>
<ul>
<li class="chapter" data-level="9.1" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#learning-objectives-9"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#prerequisites-4"><i class="fa fa-check"></i><b>9.2</b> Prerequisites</a></li>
<li class="chapter" data-level="9.3" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#resampling-cross-validation"><i class="fa fa-check"></i><b>9.3</b> Resampling &amp; cross-validation</a></li>
<li class="chapter" data-level="9.4" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>9.4</b> K-fold cross-validation</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#knowledge-check-15"><i class="fa fa-check"></i><b>9.4.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#bootstrap-resampling"><i class="fa fa-check"></i><b>9.5</b> Bootstrap resampling</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#knowledge-check-16"><i class="fa fa-check"></i><b>9.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#alternative-methods"><i class="fa fa-check"></i><b>9.6</b> Alternative methods</a></li>
<li class="chapter" data-level="9.7" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#exercises-5"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Module 4</b></span></li>
<li class="chapter" data-level="10" data-path="overview-3.html"><a href="overview-3.html"><i class="fa fa-check"></i><b>10</b> Overview</a>
<ul>
<li class="chapter" data-level="10.1" data-path="overview-3.html"><a href="overview-3.html#learning-objectives-10"><i class="fa fa-check"></i><b>10.1</b> Learning objectives</a></li>
<li class="chapter" data-level="10.2" data-path="overview-3.html"><a href="overview-3.html#estimated-time-requirement-3"><i class="fa fa-check"></i><b>10.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="10.3" data-path="overview-3.html"><a href="overview-3.html#tasks-3"><i class="fa fa-check"></i><b>10.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html"><i class="fa fa-check"></i><b>11</b> Lesson 4a: Logistic Regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#learning-objectives-11"><i class="fa fa-check"></i><b>11.1</b> Learning objectives</a></li>
<li class="chapter" data-level="11.2" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#prerequisites-5"><i class="fa fa-check"></i><b>11.2</b> Prerequisites</a></li>
<li class="chapter" data-level="11.3" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#why-logistic-regression"><i class="fa fa-check"></i><b>11.3</b> Why logistic regression</a></li>
<li class="chapter" data-level="11.4" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#simple-logistic-regression"><i class="fa fa-check"></i><b>11.4</b> Simple logistic regression</a></li>
<li class="chapter" data-level="11.5" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#interpretation"><i class="fa fa-check"></i><b>11.5</b> Interpretation</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-17"><i class="fa fa-check"></i><b>11.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>11.6</b> Multiple logistic regression</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-18"><i class="fa fa-check"></i><b>11.6.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#assessing-model-accuracy-1"><i class="fa fa-check"></i><b>11.7</b> Assessing model accuracy</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#accuracy"><i class="fa fa-check"></i><b>11.7.1</b> Accuracy</a></li>
<li class="chapter" data-level="11.7.2" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#confusion-matrix"><i class="fa fa-check"></i><b>11.7.2</b> Confusion matrix</a></li>
<li class="chapter" data-level="11.7.3" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#area-under-the-curve"><i class="fa fa-check"></i><b>11.7.3</b> Area under the curve</a></li>
<li class="chapter" data-level="11.7.4" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-19"><i class="fa fa-check"></i><b>11.7.4</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#cross-validation-performance"><i class="fa fa-check"></i><b>11.8</b> Cross-validation performance</a>
<ul>
<li class="chapter" data-level="11.8.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-20"><i class="fa fa-check"></i><b>11.8.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#feature-interpretation"><i class="fa fa-check"></i><b>11.9</b> Feature interpretation</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-21"><i class="fa fa-check"></i><b>11.9.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#final-thoughts"><i class="fa fa-check"></i><b>11.10</b> Final thoughts</a></li>
<li class="chapter" data-level="11.11" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#exercises-6"><i class="fa fa-check"></i><b>11.11</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Additional Content</b></span></li>
<li class="chapter" data-level="" data-path="computing-environment.html"><a href="computing-environment.html"><i class="fa fa-check"></i>Computing Environment</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://www.uc.edu/" target="blank">University of Cincinnati</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Mining with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lesson-2a-simple-linear-regression" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> Lesson 2a: Simple linear regression<a href="lesson-2a-simple-linear-regression.html#lesson-2a-simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_kilqm1ai&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_jvwt0cxy" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080: Intro to Simple Linear Regression">
</iframe>
</div>
<p><em>Linear regression</em>, a staple of classical statistical modeling, is one of the simplest algorithms for doing supervised learning. Though it may seem somewhat dull compared to some of the more modern statistical learning approaches described in later modules, linear regression is still a useful and widely applied statistical learning method. Moreover, it serves as a good starting point for more advanced approaches because many of the more sophisticated statistical learning approaches can be seen as generalizations to or extensions of ordinary linear regression. Consequently, it is important to have a good understanding of linear regression before studying more complex learning methods.</p>
<div class="note">
<p>
This lesson introduces simple linear regression with an emphasis on
prediction, rather than explanation.
</p>
<ol style="list-style-type: decimal">
<li>
<p>
<strong>Modeling for explanation</strong>: When you want to
explicitly describe and quantify the relationship between the outcome
variable <span class="math inline"><span class="math inline">\(y\)</span></span> and a set of explanatory
variables <span class="math inline"><span class="math inline">\(x\)</span></span>, determine the
significance of any relationships, have measures summarizing these
relationships, and possibly identify any causal relationships between
the variables.
</p>
</li>
<li>
<p>
<strong>Modeling for prediction</strong>: When you want to
predict an outcome variable <span class="math inline"><span class="math inline">\(y\)</span></span> based
on the information contained in a set of predictor variables <span class="math inline"><span class="math inline">\(x\)</span></span>. Unlike modeling for explanation,
however, you don’t care so much about understanding how all the
variables relate and interact with one another, but rather only whether
you can make good predictions about <span class="math inline"><span class="math inline">\(y\)</span></span> using the information in <span class="math inline"><span class="math inline">\(x\)</span></span>.
</p>
</li>
</ol>
<p>
Check out <span class="citation"><span class="citation">Lipovetsky (<a href="#ref-lipovetsky2020statistical" role="doc-biblioref">2020</a>)</span></span>
for a great introduction to linear regression for explanation.
</p>
</div>
<div id="learning-objectives-5" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Learning objectives<a href="lesson-2a-simple-linear-regression.html#learning-objectives-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>By the end of this lesson you will know how to:</p>
<ul>
<li>Fit a simple linear regression model.</li>
<li>Interpret results of a simple linear regression model.</li>
<li>Assess the performance of a simple linear regression model.</li>
</ul>
</div>
<div id="prerequisites-1" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Prerequisites<a href="lesson-2a-simple-linear-regression.html#prerequisites-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This lesson leverages the following packages:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="lesson-2a-simple-linear-regression.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data wrangling &amp; visualization packages</span></span>
<span id="cb24-2"><a href="lesson-2a-simple-linear-regression.html#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb24-3"><a href="lesson-2a-simple-linear-regression.html#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="lesson-2a-simple-linear-regression.html#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Modeling packages</span></span>
<span id="cb24-5"><a href="lesson-2a-simple-linear-regression.html#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span></code></pre></div>
<p>We’ll also continue working with the <code>ames</code> data set:</p>
<div class="note">
<p>
Take a minute to check out the Ames data from
<code>AmesHousing::make_ames()</code>. It is very similar to the Ames
data provided in the CSV. Note that the various quality/condition
variables (i.e. <code>Overall_Qual</code>) are already encoded as
ordinal factors.
</p>
</div>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="lesson-2a-simple-linear-regression.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># stratified sampling with the rsample package</span></span>
<span id="cb25-2"><a href="lesson-2a-simple-linear-regression.html#cb25-2" aria-hidden="true" tabindex="-1"></a>ames <span class="ot">&lt;-</span> AmesHousing<span class="sc">::</span><span class="fu">make_ames</span>()</span>
<span id="cb25-3"><a href="lesson-2a-simple-linear-regression.html#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="lesson-2a-simple-linear-regression.html#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb25-5"><a href="lesson-2a-simple-linear-regression.html#cb25-5" aria-hidden="true" tabindex="-1"></a>split  <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(ames, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> <span class="st">&quot;Sale_Price&quot;</span>)</span>
<span id="cb25-6"><a href="lesson-2a-simple-linear-regression.html#cb25-6" aria-hidden="true" tabindex="-1"></a>ames_train  <span class="ot">&lt;-</span> <span class="fu">training</span>(split)</span>
<span id="cb25-7"><a href="lesson-2a-simple-linear-regression.html#cb25-7" aria-hidden="true" tabindex="-1"></a>ames_test   <span class="ot">&lt;-</span> <span class="fu">testing</span>(split)</span></code></pre></div>
</div>
<div id="correlation" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Correlation<a href="lesson-2a-simple-linear-regression.html#correlation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_b03wfof2&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_3du3onvl" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080: Correlation">
</iframe>
</div>
<p>Correlation is a single-number statistic that measures the extent that two variables are related (“co-related”) to one another. For example, say we want to understand the relationship between the total above ground living space of a home (<code>Gr_Liv_Area</code>) and the home’s sale price (<code>Sale_Price</code>).</p>
<p>Looking at the following scatter plot we can see that some relationship does exist. It appears that as <code>Gr_Liv_Area</code> increases the <code>Sale_Price</code> of a home increases as well.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="lesson-2a-simple-linear-regression.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ames_train, <span class="fu">aes</span>(Gr_Liv_Area, Sale_Price)) <span class="sc">+</span></span>
<span id="cb26-2"><a href="lesson-2a-simple-linear-regression.html#cb26-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> .<span class="dv">25</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-68-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Correlation allows us to quantify this relationship. We can compute the correlation with the following:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="lesson-2a-simple-linear-regression.html#cb27-1" aria-hidden="true" tabindex="-1"></a>ames_train <span class="sc">%&gt;%</span></span>
<span id="cb27-2"><a href="lesson-2a-simple-linear-regression.html#cb27-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">summarize</span>(<span class="at">correlation =</span> <span class="fu">cor</span>(Gr_Liv_Area, Sale_Price))</span>
<span id="cb27-3"><a href="lesson-2a-simple-linear-regression.html#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 1 × 1</span></span>
<span id="cb27-4"><a href="lesson-2a-simple-linear-regression.html#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="do">##   correlation</span></span>
<span id="cb27-5"><a href="lesson-2a-simple-linear-regression.html#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="do">##         &lt;dbl&gt;</span></span>
<span id="cb27-6"><a href="lesson-2a-simple-linear-regression.html#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       0.708</span></span></code></pre></div>
<p>The value of the correlation coefficient varies between +1 and -1. In our example, the correlation coefficient is 0.71. When the value of the correlation coefficient lies around ±1, then it is said to be a perfect degree of association between the two variables (near +1 implies a strong positive association and near -1 implies a strong negative association). As the correlation coefficient nears 0, the relationship between the two variables weakens with a near 0 value implying no association between the two variables.</p>
<p>So, in our case we could say we have a moderate positive correlation between <code>Gr_Liv_Area</code> and <code>Sale_Price</code>. Let’s look at another relationship. In the following we look at the relationship between the unfinished basement square footage of homes (<code>Bsmt_Unf_SF</code>) and the <code>Sale_Price</code>.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="lesson-2a-simple-linear-regression.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ames_train, <span class="fu">aes</span>(Bsmt_Unf_SF, Sale_Price)) <span class="sc">+</span></span>
<span id="cb28-2"><a href="lesson-2a-simple-linear-regression.html#cb28-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> .<span class="dv">25</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-70-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>In this example, we don’t see much of a relationship. Basically, as <code>Bsmt_Unf_SF</code> gets larger or smaller, we really don’t see a strong pattern with <code>Sale_Price</code>.</p>
<p>If we look at the correlation for this relationship, we see that the correlation coefficient is much closer to zero than to 1. This confirms our visual assessment that there does not seem to be much of a relationship between these two variables.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="lesson-2a-simple-linear-regression.html#cb29-1" aria-hidden="true" tabindex="-1"></a>ames_train <span class="sc">%&gt;%</span></span>
<span id="cb29-2"><a href="lesson-2a-simple-linear-regression.html#cb29-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">summarize</span>(<span class="at">correlation =</span> <span class="fu">cor</span>(Bsmt_Unf_SF, Sale_Price))</span>
<span id="cb29-3"><a href="lesson-2a-simple-linear-regression.html#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 1 × 1</span></span>
<span id="cb29-4"><a href="lesson-2a-simple-linear-regression.html#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="do">##   correlation</span></span>
<span id="cb29-5"><a href="lesson-2a-simple-linear-regression.html#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="do">##         &lt;dbl&gt;</span></span>
<span id="cb29-6"><a href="lesson-2a-simple-linear-regression.html#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       0.186</span></span></code></pre></div>
<div id="knowledge-check-7" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Knowledge check<a href="lesson-2a-simple-linear-regression.html#knowledge-check-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="todo">
<ol style="list-style-type: decimal">
<li>
Interpreting coefficients that are not close to the extreme values
of -1, 0, and 1 can be somewhat subjective. To help develop your sense
of correlation coefficients, we suggest you play the 80s-style video
game called, “Guess the Correlation”, at <a
href="http://guessthecorrelation.com/"
class="uri">http://guessthecorrelation.com/</a>
</li>
<li>
Using the <code>ames_train</code> data, visualize the relationship
between <code>Year_Built</code> and <code>Sale_Price</code>.
</li>
<li>
Guess what the correlation is between these two variables?
</li>
<li>
Now compute the correlation between these two variables.
</li>
</ol>
</div>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_chgb9tye&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_zqi7wpy6" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080: Knowledge check 5.3.1">
</iframe>
</div>
<p>Although a useful measure, correlation can be hard to imagine exactly what the association is between two variables based on this single statistic. Moreover, its important to realize that correlation assumes a <strong>linear</strong> relationship between two variables.</p>
<p>For example, let’s check out the <code>anscombe</code> data, which is a built-in data set provided in R. If we look at each <code>x</code> and <code>y</code> relationship visually, we can see significant differences:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="lesson-2a-simple-linear-regression.html#cb30-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(<span class="at">x =</span> x1, <span class="at">y =</span> y1, <span class="at">data =</span> anscombe)</span>
<span id="cb30-2"><a href="lesson-2a-simple-linear-regression.html#cb30-2" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(<span class="at">x =</span> x2, <span class="at">y =</span> y2, <span class="at">data =</span> anscombe)</span>
<span id="cb30-3"><a href="lesson-2a-simple-linear-regression.html#cb30-3" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(<span class="at">x =</span> x3, <span class="at">y =</span> y3, <span class="at">data =</span> anscombe)</span>
<span id="cb30-4"><a href="lesson-2a-simple-linear-regression.html#cb30-4" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(<span class="at">x =</span> x4, <span class="at">y =</span> y4, <span class="at">data =</span> anscombe)</span>
<span id="cb30-5"><a href="lesson-2a-simple-linear-regression.html#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="lesson-2a-simple-linear-regression.html#cb30-6" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1, p2, p3, p4, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-74-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>However, if we compute the correlation between each of these relationships we see that they all have nearly equal correlation coefficients!</p>
<div class="tip">
<p>
Never take a correlation coefficient at face value! You should always
compare the visual relationship with the computed correlation value.
</p>
</div>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="lesson-2a-simple-linear-regression.html#cb31-1" aria-hidden="true" tabindex="-1"></a>anscombe <span class="sc">%&gt;%</span></span>
<span id="cb31-2"><a href="lesson-2a-simple-linear-regression.html#cb31-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">summarize</span>(</span>
<span id="cb31-3"><a href="lesson-2a-simple-linear-regression.html#cb31-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">corr_x1_y1 =</span> <span class="fu">cor</span>(x1, y1),</span>
<span id="cb31-4"><a href="lesson-2a-simple-linear-regression.html#cb31-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">corr_x2_y2 =</span> <span class="fu">cor</span>(x2, y2),</span>
<span id="cb31-5"><a href="lesson-2a-simple-linear-regression.html#cb31-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">corr_x3_y3 =</span> <span class="fu">cor</span>(x3, y3),</span>
<span id="cb31-6"><a href="lesson-2a-simple-linear-regression.html#cb31-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">corr_x4_y4 =</span> <span class="fu">cor</span>(x4, y4)</span>
<span id="cb31-7"><a href="lesson-2a-simple-linear-regression.html#cb31-7" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb31-8"><a href="lesson-2a-simple-linear-regression.html#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="do">##   corr_x1_y1 corr_x2_y2 corr_x3_y3 corr_x4_y4</span></span>
<span id="cb31-9"><a href="lesson-2a-simple-linear-regression.html#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 1  0.8164205  0.8162365  0.8162867  0.8165214</span></span></code></pre></div>
<div class="note">
<p>
There are actually several different ways to measure correlation. The
most common, and the one we’ve been using here, is Pearson’s
correlation. Alternative methods allow us to loosen some assumptions
such as assuming a linear relationship. You can read more at <a
href="http://uc-r.github.io/correlations"
class="uri">http://uc-r.github.io/correlations</a>.
</p>
</div>
</div>
</div>
<div id="simple-linear-regression" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Simple linear regression<a href="lesson-2a-simple-linear-regression.html#simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_qw1ecepp&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_ywfw2mos" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080: Simple linear regression">
</iframe>
</div>
<p>As discussed in the last section, correlation is often used to quantify the strength of the linear association between two continuous variables. However, this statistic alone does not provide us with a lot of actionable insights. But we can build on the concept of correlation to provide us with more useful information.</p>
<p>In this section, we seek to fully characterize the linear relationship we measured with correlation using a method called <em>simple linear regression</em> (SLR).</p>
<div id="best-fit-line" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Best fit line<a href="lesson-2a-simple-linear-regression.html#best-fit-line" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s go back to our plot illustrating the relationship between <code>Gr_Liv_Area</code> and <code>Sale_Price</code>. We can characterize this relationship with a linear line that we consider is the “best-fitting” line (we’ll define “best-fitting” in a little bit). We do this by adding overplotting with <code>geom_smooth(method = "lm", se = FALSE)</code></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="lesson-2a-simple-linear-regression.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ames_train, <span class="fu">aes</span>(Gr_Liv_Area, Sale_Price)) <span class="sc">+</span></span>
<span id="cb32-2"><a href="lesson-2a-simple-linear-regression.html#cb32-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> .<span class="dv">25</span>) <span class="sc">+</span></span>
<span id="cb32-3"><a href="lesson-2a-simple-linear-regression.html#cb32-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-79-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The line in the above plot is called a “regression line.” The regression line is a visual summary of the relationship between two numerical variables, in our case the outcome variable <code>Sale_Price</code> and the explanatory variable <code>Gr_Liv_Area</code>. The positive slope of the blue line is consistent with our earlier observed correlation coefficient of 0.71 suggesting that there is a positive relationship between these two variables.</p>
</div>
<div id="estimating-best-fit" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Estimating “best fit”<a href="lesson-2a-simple-linear-regression.html#estimating-best-fit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You may recall from secondary/high school algebra that the equation of a line is <span class="math inline">\(y = a + b \times x\)</span>. Often, in formulas like these we illustrate multiplication without the <span class="math inline">\(\times\)</span> symbol like the following <span class="math inline">\(y = a + bx\)</span>. The equation of our line is defined by two coefficients <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. The intercept coefficient <span class="math inline">\(a\)</span> is the value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x = 0\)</span>. The slope coefficient <span class="math inline">\(b\)</span> for <span class="math inline">\(x\)</span> is the increase in <span class="math inline">\(y\)</span> for every increase of one in <span class="math inline">\(x\)</span>. This is also called the “rise over run.”</p>
<p>However, when defining a regression line like the regression line in the previous plot, we use slightly different notation: the equation of the regression line is <span class="math inline">\(\widehat{y} = b_0 + b_1 x\)</span>. The intercept coefficient is <span class="math inline">\(b_0\)</span>, so <span class="math inline">\(b_0\)</span> is the value of <span class="math inline">\(\widehat{y}\)</span> when <span class="math inline">\(x = 0\)</span>. The slope coefficient for <span class="math inline">\(x\)</span> is <span class="math inline">\(b_1\)</span>, i.e., the increase in <span class="math inline">\(\widehat{y}\)</span> for every increase of one unit in <span class="math inline">\(x\)</span>. Why do we put a “hat” on top of the <span class="math inline">\(y\)</span>? It’s a form of notation commonly used in regression to indicate that we have a “fitted value,” or the value of <span class="math inline">\(y\)</span> on the regression line for a given <span class="math inline">\(x\)</span> value.</p>
<p>So what are the coefficients of our best fit line that characterizes the relationship between <code>Gr_Liv_Area</code> and <code>Sale_Price</code>? We can get that by fitting an SLR model where <code>Sale_Price</code> is our response variable and <code>Gr_Liv_Area</code> is our single predictor variable.</p>
<p>Once our model is fit we can extract our fitted model results with <code>tidy()</code>:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="lesson-2a-simple-linear-regression.html#cb33-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb33-2"><a href="lesson-2a-simple-linear-regression.html#cb33-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">fit</span>(Sale_Price <span class="sc">~</span> Gr_Liv_Area, <span class="at">data =</span> ames_train)</span>
<span id="cb33-3"><a href="lesson-2a-simple-linear-regression.html#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="lesson-2a-simple-linear-regression.html#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(model1)</span>
<span id="cb33-5"><a href="lesson-2a-simple-linear-regression.html#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 2 × 5</span></span>
<span id="cb33-6"><a href="lesson-2a-simple-linear-regression.html#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="do">##   term        estimate std.error statistic   p.value</span></span>
<span id="cb33-7"><a href="lesson-2a-simple-linear-regression.html#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb33-8"><a href="lesson-2a-simple-linear-regression.html#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 (Intercept)   15938.   3852.        4.14 3.65e-  5</span></span>
<span id="cb33-9"><a href="lesson-2a-simple-linear-regression.html#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Gr_Liv_Area     110.      2.42     45.3  5.17e-311</span></span></code></pre></div>
<p>The estimated coefficients from our model are <span class="math inline">\(b_0 =\)</span> 15938.17 and <span class="math inline">\(b_1 =\)</span> 109.67. To interpret, we estimate that the mean selling price increases by 109.67 for each additional one square foot of above ground living space.</p>
<p>With these coefficients, we can look at our scatter plot again (this time with the x &amp; y axes formatted) and compare the characterization of our linear line with the coefficients. This simple description of the relationship between the sale price and square footage using a single number (i.e., the slope) is what makes linear regression such an intuitive and popular modeling tool.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="lesson-2a-simple-linear-regression.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ames_train, <span class="fu">aes</span>(Gr_Liv_Area, Sale_Price)) <span class="sc">+</span></span>
<span id="cb34-2"><a href="lesson-2a-simple-linear-regression.html#cb34-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> .<span class="dv">25</span>) <span class="sc">+</span></span>
<span id="cb34-3"><a href="lesson-2a-simple-linear-regression.html#cb34-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb34-4"><a href="lesson-2a-simple-linear-regression.html#cb34-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">scale_x_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>comma) <span class="sc">+</span></span>
<span id="cb34-5"><a href="lesson-2a-simple-linear-regression.html#cb34-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>dollar)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-81-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>This is great but you may still be asking how we are estimating the coefficients? Ideally, we want estimates of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> that give us the “best fitting” line. But what is meant by “best fitting”? The most common approach is to use the method of <em>least squares</em> (LS) estimation; this form of linear regression is often referred to as ordinary least squares (OLS) regression. There are multiple ways to measure “best fitting”, but the LS criterion finds the “best fitting” line by minimizing the <em>residual sum of squares</em> (RSS).</p>
<p>Before we define RSS, let’s first define what a residual is. Let’s look at a single home. This home has 3,608 square feet of living space and sold for $475,000. In other words, <span class="math inline">\(x = 3608\)</span> and <span class="math inline">\(y = 475000\)</span>.</p>
<pre><code>## # A tibble: 1 × 2
##   Gr_Liv_Area Sale_Price
##         &lt;int&gt;      &lt;int&gt;
## 1        3608     475000</code></pre>
<p>Based on our linear regression model (or the intercept and slope we identified from our model) our best fit line estimates that this house’s sale price is</p>
<p><span class="math display">\[\widehat{y} = b_0 + b_1 \times x = 15938.1733 + 109.6675 \times 3608 = 411618.5\]</span></p>
<p>We can visualize this in our plot where we have the actual <code>Sale_Price</code> (orange) and the estimated <code>Sale_Price</code> based on our fitted line. The difference between these two values (<span class="math inline">\(y - \widehat{y} = 475000 - 411618.5 = 63381.5\)</span>) is what we call our residual. It is considered the error for this observation, which we can visualize with the red line.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-83-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Now, if we look across all our data points you will see that each one has a residual associated with it. In the right plot, the vertical lines represent the individual residuals/errors associated with each observation.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lm-visualize-model1"></span>
<img src="_main_files/figure-html/lm-visualize-model1-1.png" alt="The least squares fit from regressing sale price on living space for the the Ames housing data. Left: Fitted regression line. Right: Fitted regression line with vertical grey bars representing the residuals." width="960" />
<p class="caption">
Figure 5.1: The least squares fit from regressing sale price on living space for the the Ames housing data. Left: Fitted regression line. Right: Fitted regression line with vertical grey bars representing the residuals.
</p>
</div>
<p>The OLS criterion identifies the “best fitting” line that minimizes the sum of squares of these residuals. Mathematically, this is computed by taking the sum of the squared residuals (or as stated before the residual sum of squares –&gt; “RSS”).</p>
<p><span class="math display">\[\begin{equation}
  RSS = \sum_{i=1}^n\left(y_i - \widehat{y_i}\right)^2
\end{equation}\]</span></p>
<p>where <span class="math inline">\(y_i\)</span> and <span class="math inline">\(\widehat{y_i}\)</span> just mean the actual and predicted response values for the ith observation.</p>
</div>
<div id="inference" class="section level3 hasAnchor" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Inference<a href="lesson-2a-simple-linear-regression.html#inference" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s go back to our <code>model1</code> results that show the <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> coefficient values:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="lesson-2a-simple-linear-regression.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(model1)</span>
<span id="cb36-2"><a href="lesson-2a-simple-linear-regression.html#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 2 × 5</span></span>
<span id="cb36-3"><a href="lesson-2a-simple-linear-regression.html#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="do">##   term        estimate std.error statistic   p.value</span></span>
<span id="cb36-4"><a href="lesson-2a-simple-linear-regression.html#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="do">##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb36-5"><a href="lesson-2a-simple-linear-regression.html#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 (Intercept)   15938.   3852.        4.14 3.65e-  5</span></span>
<span id="cb36-6"><a href="lesson-2a-simple-linear-regression.html#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 2 Gr_Liv_Area     110.      2.42     45.3  5.17e-311</span></span></code></pre></div>
<p>Note that we call these coefficient values “estimates.” Due to various reasons we should always assume that there is some variability in our estimated coefficient values. The variability of an estimate is often measured by its <em>standard error</em> (SE). When we fit our linear regression model the SE for each coefficient was computed for us and are displayed in the column labeled <code>std.error</code> in the output from <code>tidy()</code>.</p>
<p>From this, we can also derive simple <span class="math inline">\(t\)</span>-tests to understand if the individual coefficients are statistically significant from zero. The <em>t</em>-statistics for such a test are nothing more than the estimated coefficients divided by their corresponding estimated standard errors (i.e., in the output from <code>tidy()</code>, <code>t value (aka statistic)</code> = <code>estimate</code> / <code>std.error</code>). The reported <em>t</em>-statistics measure the number of standard deviations each coefficient is away from 0. Thus, large <em>t</em>-statistics (greater than two in absolute value, say) roughly indicate statistical significance at the <span class="math inline">\(\alpha = 0.05\)</span> level. The <em>p</em>-values for these tests are also reported by <code>tidy()</code> in the column labeled <code>p.value</code>.</p>
<div class="note">
<p>
This may seem quite complicated but don’t worry, R will do the heavy
lifting for us. Just realize we can use these additional statistics
provided in our model summary to tell us if the predictor variable
(<code>Gr_Liv_Area</code> in our example) has a statistically
significant relationship with our response variable.
</p>
</div>
<p>When the <code>p.value</code> for a given coefficient is quite small (i.e. <code>p.value</code> &lt; 0.005), that is a good indication that the estimate for that coefficient is statistically different than zero. For example, the <code>p.value</code> for the <code>Gr_Liv_Area</code> coefficient is 5.17e-311 (basically zero). This means that the estimated coefficient value of 109.6675 is statistically different than zero.
Let’s look at this from another perspective. We can compute the 95% confidence intervals for the coefficients in our SLR example.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="lesson-2a-simple-linear-regression.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(model1<span class="sc">$</span>fit, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb37-2"><a href="lesson-2a-simple-linear-regression.html#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                2.5 %     97.5 %</span></span>
<span id="cb37-3"><a href="lesson-2a-simple-linear-regression.html#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept) 8384.213 23492.1336</span></span>
<span id="cb37-4"><a href="lesson-2a-simple-linear-regression.html#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Gr_Liv_Area  104.920   114.4149</span></span></code></pre></div>
<p>To interpret, we estimate with 95% confidence that the mean selling price increases between 104.92 and 114.41 for each additional one square foot of above ground living space. We can also conclude that the slope <span class="math inline">\(b_1\)</span> is significantly different from zero (or any other pre-specified value not included in the interval) at the <span class="math inline">\(\alpha = 0.05\)</span> level (<span class="math inline">\(\alpha = 0.05\)</span> because we just take 1 - confidence level we are computing so <span class="math inline">\(1 - 0.95 = 0.05\)</span>).</p>
</div>
<div id="knowledge-check-8" class="section level3 hasAnchor" number="5.4.4">
<h3><span class="header-section-number">5.4.4</span> Knowledge check<a href="lesson-2a-simple-linear-regression.html#knowledge-check-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="todo">
<p>
Let’s revisit the relationship between <code>Year_Built</code> and
<code>Sale_Price</code>. Using the <code>ames_train</code> data:
</p>
<ol style="list-style-type: decimal">
<li>
Visualize the relationship between these two variables.
</li>
<li>
Compute their correlation.
</li>
<li>
Create a simple linear regression model where
<code>Sale_Price</code> is a function of <code>Year_Built</code>.
</li>
<li>
Interpret the coefficient for <code>Year_Built</code>.
</li>
<li>
What is the 95% confidence interval for this coefficient and can we
confidently say it is statistically different than zero?
</li>
</ol>
</div>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_8vp4c6hg&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_jiy7izms" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080: Knowledge check 5.4.4">
</iframe>
</div>
</div>
</div>
<div id="making-predictions-1" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Making predictions<a href="lesson-2a-simple-linear-regression.html#making-predictions-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We’ve created a simple linear regression model to describe the relationship between <code>Gr_Liv_Area</code> and <code>Sale_Price</code>. As we saw in the last module, we can make predictions with this model.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="lesson-2a-simple-linear-regression.html#cb38-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="sc">%&gt;%</span></span>
<span id="cb38-2"><a href="lesson-2a-simple-linear-regression.html#cb38-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">predict</span>(ames_train)</span>
<span id="cb38-3"><a href="lesson-2a-simple-linear-regression.html#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 2,049 × 1</span></span>
<span id="cb38-4"><a href="lesson-2a-simple-linear-regression.html#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="do">##      .pred</span></span>
<span id="cb38-5"><a href="lesson-2a-simple-linear-regression.html#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="do">##      &lt;dbl&gt;</span></span>
<span id="cb38-6"><a href="lesson-2a-simple-linear-regression.html#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="do">##  1 135695.</span></span>
<span id="cb38-7"><a href="lesson-2a-simple-linear-regression.html#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="do">##  2 135695.</span></span>
<span id="cb38-8"><a href="lesson-2a-simple-linear-regression.html#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="do">##  3 107620.</span></span>
<span id="cb38-9"><a href="lesson-2a-simple-linear-regression.html#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="do">##  4  98408.</span></span>
<span id="cb38-10"><a href="lesson-2a-simple-linear-regression.html#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="do">##  5 126922.</span></span>
<span id="cb38-11"><a href="lesson-2a-simple-linear-regression.html#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="do">##  6 224526.</span></span>
<span id="cb38-12"><a href="lesson-2a-simple-linear-regression.html#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="do">##  7 114639.</span></span>
<span id="cb38-13"><a href="lesson-2a-simple-linear-regression.html#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="do">##  8 129992.</span></span>
<span id="cb38-14"><a href="lesson-2a-simple-linear-regression.html#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="do">##  9 205444.</span></span>
<span id="cb38-15"><a href="lesson-2a-simple-linear-regression.html#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="do">## 10 132515.</span></span>
<span id="cb38-16"><a href="lesson-2a-simple-linear-regression.html#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="do">## # … with 2,039 more rows</span></span>
<span id="cb38-17"><a href="lesson-2a-simple-linear-regression.html#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="do">## # ℹ Use `print(n = ...)` to see more rows</span></span></code></pre></div>
<p>And we can always add these predictions back to our training data if we want to look at how the predicted values differ from the actual values.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="lesson-2a-simple-linear-regression.html#cb39-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="sc">%&gt;%</span></span>
<span id="cb39-2"><a href="lesson-2a-simple-linear-regression.html#cb39-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">predict</span>(ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb39-3"><a href="lesson-2a-simple-linear-regression.html#cb39-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">bind_cols</span>(ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb39-4"><a href="lesson-2a-simple-linear-regression.html#cb39-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">select</span>(Gr_Liv_Area, Sale_Price, .pred)</span>
<span id="cb39-5"><a href="lesson-2a-simple-linear-regression.html#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 2,049 × 3</span></span>
<span id="cb39-6"><a href="lesson-2a-simple-linear-regression.html#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="do">##    Gr_Liv_Area Sale_Price   .pred</span></span>
<span id="cb39-7"><a href="lesson-2a-simple-linear-regression.html#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="do">##          &lt;int&gt;      &lt;int&gt;   &lt;dbl&gt;</span></span>
<span id="cb39-8"><a href="lesson-2a-simple-linear-regression.html#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="do">##  1        1092     105500 135695.</span></span>
<span id="cb39-9"><a href="lesson-2a-simple-linear-regression.html#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="do">##  2        1092      88000 135695.</span></span>
<span id="cb39-10"><a href="lesson-2a-simple-linear-regression.html#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="do">##  3         836     120000 107620.</span></span>
<span id="cb39-11"><a href="lesson-2a-simple-linear-regression.html#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="do">##  4         752     125000  98408.</span></span>
<span id="cb39-12"><a href="lesson-2a-simple-linear-regression.html#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="do">##  5        1012      67500 126922.</span></span>
<span id="cb39-13"><a href="lesson-2a-simple-linear-regression.html#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="do">##  6        1902     112000 224526.</span></span>
<span id="cb39-14"><a href="lesson-2a-simple-linear-regression.html#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="do">##  7         900     122000 114639.</span></span>
<span id="cb39-15"><a href="lesson-2a-simple-linear-regression.html#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="do">##  8        1040     127000 129992.</span></span>
<span id="cb39-16"><a href="lesson-2a-simple-linear-regression.html#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="do">##  9        1728      84900 205444.</span></span>
<span id="cb39-17"><a href="lesson-2a-simple-linear-regression.html#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="do">## 10        1063     128000 132515.</span></span>
<span id="cb39-18"><a href="lesson-2a-simple-linear-regression.html#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="do">## # … with 2,039 more rows</span></span>
<span id="cb39-19"><a href="lesson-2a-simple-linear-regression.html#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="do">## # ℹ Use `print(n = ...)` to see more rows</span></span></code></pre></div>
</div>
<div id="assessing-model-accuracy" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Assessing model accuracy<a href="lesson-2a-simple-linear-regression.html#assessing-model-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_pi5lz6iq&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_2eboh1wo" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080: Simple linear regression model performance">
</iframe>
</div>
<p>This allows us to assess the accuracy of our model. Recall from the last module that for regression models we often use mean squared error (MSE) and root mean squared error (RMSE) to quantify the accuracy of our model. These two values are directly correlated to the RSS we discussed above, which determines the best fit line. Let’s illustrate.</p>
<div id="training-data-accuracy" class="section level3 hasAnchor" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Training data accuracy<a href="lesson-2a-simple-linear-regression.html#training-data-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that the residuals are the differences between the actual <span class="math inline">\(y\)</span> and the estimated <span class="math inline">\(\widehat{y}\)</span> based on the best fit line.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="lesson-2a-simple-linear-regression.html#cb40-1" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> model1 <span class="sc">%&gt;%</span></span>
<span id="cb40-2"><a href="lesson-2a-simple-linear-regression.html#cb40-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">predict</span>(ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb40-3"><a href="lesson-2a-simple-linear-regression.html#cb40-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">bind_cols</span>(ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb40-4"><a href="lesson-2a-simple-linear-regression.html#cb40-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">select</span>(Gr_Liv_Area, Sale_Price, .pred) <span class="sc">%&gt;%</span></span>
<span id="cb40-5"><a href="lesson-2a-simple-linear-regression.html#cb40-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(<span class="at">residual =</span> Sale_Price <span class="sc">-</span> .pred)</span>
<span id="cb40-6"><a href="lesson-2a-simple-linear-regression.html#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="lesson-2a-simple-linear-regression.html#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(residuals, <span class="dv">5</span>)</span>
<span id="cb40-8"><a href="lesson-2a-simple-linear-regression.html#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 5 × 4</span></span>
<span id="cb40-9"><a href="lesson-2a-simple-linear-regression.html#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="do">##   Gr_Liv_Area Sale_Price   .pred residual</span></span>
<span id="cb40-10"><a href="lesson-2a-simple-linear-regression.html#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="do">##         &lt;int&gt;      &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb40-11"><a href="lesson-2a-simple-linear-regression.html#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 1        1092     105500 135695.  -30195.</span></span>
<span id="cb40-12"><a href="lesson-2a-simple-linear-regression.html#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 2        1092      88000 135695.  -47695.</span></span>
<span id="cb40-13"><a href="lesson-2a-simple-linear-regression.html#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 3         836     120000 107620.   12380.</span></span>
<span id="cb40-14"><a href="lesson-2a-simple-linear-regression.html#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 4         752     125000  98408.   26592.</span></span>
<span id="cb40-15"><a href="lesson-2a-simple-linear-regression.html#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="do">## 5        1012      67500 126922.  -59422.</span></span></code></pre></div>
<p>The RSS squares these values and then sums them.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="lesson-2a-simple-linear-regression.html#cb41-1" aria-hidden="true" tabindex="-1"></a>residuals <span class="sc">%&gt;%</span></span>
<span id="cb41-2"><a href="lesson-2a-simple-linear-regression.html#cb41-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(<span class="at">squared_residuals =</span> residual<span class="sc">^</span><span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb41-3"><a href="lesson-2a-simple-linear-regression.html#cb41-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">summarize</span>(<span class="at">sum_of_squared_residuals =</span> <span class="fu">sum</span>(squared_residuals))</span>
<span id="cb41-4"><a href="lesson-2a-simple-linear-regression.html#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 1 × 1</span></span>
<span id="cb41-5"><a href="lesson-2a-simple-linear-regression.html#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="do">##   sum_of_squared_residuals</span></span>
<span id="cb41-6"><a href="lesson-2a-simple-linear-regression.html#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="do">##                      &lt;dbl&gt;</span></span>
<span id="cb41-7"><a href="lesson-2a-simple-linear-regression.html#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 1                  6.60e12</span></span></code></pre></div>
<div class="note">
<p>
Why do we square the residuals? So that both positive and negative
deviations of the same amount are treated equally. While taking the
absolute value of the residuals would also treat both positive and
negative deviations of the same amount equally, squaring the residuals
is used for reasons related to calculus: taking derivatives and
minimizing functions. If you’d like to learn more we suggest you consult
one of the textbooks referenced at the end of the lesson.
</p>
</div>
<p>However, when expressing the performance of a model we rarely state the RSS. Instead it is more common to state the <em>average of the squared error</em>, or the MSE as discussed <a href="https://bradleyboehmke.github.io/uc-bana-4080/lesson-1b-first-model-with-tidymodels.html#regression-models">here</a>. Unfortunately, both the RSS and MSE are not very intuitive because the units the metrics are expressed in do have much meaning. So, we usually use the RMSE metric, which simply takes the square root of the MSE metric so that your error metric is in the same units as your response variable.</p>
<p>We can manually compute this with the following, which tells us that on average, our linear regression model mispredicts the expected sale price of a home by about $56,760.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="lesson-2a-simple-linear-regression.html#cb42-1" aria-hidden="true" tabindex="-1"></a>residuals <span class="sc">%&gt;%</span></span>
<span id="cb42-2"><a href="lesson-2a-simple-linear-regression.html#cb42-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(<span class="at">squared_residuals =</span> residual<span class="sc">^</span><span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb42-3"><a href="lesson-2a-simple-linear-regression.html#cb42-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">summarize</span>(</span>
<span id="cb42-4"><a href="lesson-2a-simple-linear-regression.html#cb42-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">MSE =</span> <span class="fu">mean</span>(squared_residuals),</span>
<span id="cb42-5"><a href="lesson-2a-simple-linear-regression.html#cb42-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">RMSE =</span> <span class="fu">sqrt</span>(MSE)</span>
<span id="cb42-6"><a href="lesson-2a-simple-linear-regression.html#cb42-6" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb42-7"><a href="lesson-2a-simple-linear-regression.html#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 1 × 2</span></span>
<span id="cb42-8"><a href="lesson-2a-simple-linear-regression.html#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="do">##           MSE   RMSE</span></span>
<span id="cb42-9"><a href="lesson-2a-simple-linear-regression.html#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="do">##         &lt;dbl&gt;  &lt;dbl&gt;</span></span>
<span id="cb42-10"><a href="lesson-2a-simple-linear-regression.html#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 3221722037. 56760.</span></span></code></pre></div>
<p>We could also compute this using the <code>rmse()</code> function we saw in the last module:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="lesson-2a-simple-linear-regression.html#cb43-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="sc">%&gt;%</span></span>
<span id="cb43-2"><a href="lesson-2a-simple-linear-regression.html#cb43-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">predict</span>(ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb43-3"><a href="lesson-2a-simple-linear-regression.html#cb43-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">bind_cols</span>(ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb43-4"><a href="lesson-2a-simple-linear-regression.html#cb43-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rmse</span>(<span class="at">truth =</span> Sale_Price, <span class="at">estimate =</span> .pred)</span>
<span id="cb43-5"><a href="lesson-2a-simple-linear-regression.html#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 1 × 3</span></span>
<span id="cb43-6"><a href="lesson-2a-simple-linear-regression.html#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="do">##   .metric .estimator .estimate</span></span>
<span id="cb43-7"><a href="lesson-2a-simple-linear-regression.html#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb43-8"><a href="lesson-2a-simple-linear-regression.html#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 rmse    standard      56760.</span></span></code></pre></div>
</div>
<div id="test-data-accuracy" class="section level3 hasAnchor" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Test data accuracy<a href="lesson-2a-simple-linear-regression.html#test-data-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that a major goal of the machine learning process is to find a model that most accurately predicts future values based on a set of features. In other words, we want an algorithm that not only fits well to our past data, but more importantly, one that predicts a future outcome accurately. In the last module we called this our <strong><em>generalization</em></strong> error.</p>
<p>So, ultimately, we want to understand how well our model will generalize to <em>unseen</em> data. To do this we need to compute the RMSE of our model on our test set.</p>
<div class="note">
<p>
Here, we see that our test RMSE is right around the same as our
training data. As we’ll see in later modules, this is not always the
case.
</p>
</div>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="lesson-2a-simple-linear-regression.html#cb44-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="sc">%&gt;%</span></span>
<span id="cb44-2"><a href="lesson-2a-simple-linear-regression.html#cb44-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">predict</span>(ames_test) <span class="sc">%&gt;%</span></span>
<span id="cb44-3"><a href="lesson-2a-simple-linear-regression.html#cb44-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">bind_cols</span>(ames_test) <span class="sc">%&gt;%</span></span>
<span id="cb44-4"><a href="lesson-2a-simple-linear-regression.html#cb44-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rmse</span>(<span class="at">truth =</span> Sale_Price, <span class="at">estimate =</span> .pred)</span>
<span id="cb44-5"><a href="lesson-2a-simple-linear-regression.html#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 1 × 3</span></span>
<span id="cb44-6"><a href="lesson-2a-simple-linear-regression.html#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="do">##   .metric .estimator .estimate</span></span>
<span id="cb44-7"><a href="lesson-2a-simple-linear-regression.html#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb44-8"><a href="lesson-2a-simple-linear-regression.html#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 rmse    standard      55942.</span></span></code></pre></div>
</div>
<div id="knowledge-check-9" class="section level3 hasAnchor" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> Knowledge check<a href="lesson-2a-simple-linear-regression.html#knowledge-check-9" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="todo">
<p>
Let’s revisit the simple linear regression model you created earlier
with <code>Year_Built</code> and <code>Sale_Price</code>.
</p>
<ol style="list-style-type: decimal">
<li>
Using this model, make predictions using the test data. What is the
predicted value for the first home in the test data?
</li>
<li>
Compute the <strong><em>generalization</em></strong> RMSE for this
model.
</li>
<li>
Interpret the generalization RMSE.
</li>
<li>
How does this model compare to the model based on
<code>Gr_Liv_Area</code>?
</li>
</ol>
</div>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_khp470yh&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_pg5a7mqy" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080: Knowledge check 5.6.3">
</iframe>
</div>
</div>
</div>
<div id="exercises-2" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Exercises<a href="lesson-2a-simple-linear-regression.html#exercises-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="todo">
<p>
Using the Boston housing data set where the response feature is the
median value of homes within a census tract (<code>cmedv</code>):
</p>
<ol style="list-style-type: decimal">
<li>
Split the data into 70-30 training-test sets.
</li>
<li>
Using the training data, pick a single feature variable and…
<ul>
<li>
Visualize the relationship between that feature and
<code>cmedv</code>.
</li>
<li>
Compute the correlation between that feature and
<code>cmedv</code>.
</li>
<li>
Create a simple linear regression model with <code>cmedv</code> as a
function of that feature variable.
</li>
<li>
Interpret the feature’s coefficient.
</li>
<li>
What is the model’s generalization error?
</li>
</ul>
</li>
<li>
Now pick another feature variable and repeat the process in #2.
</li>
</ol>
</div>
</div>
<div id="other-resources" class="section level2 hasAnchor" number="5.8">
<h2><span class="header-section-number">5.8</span> Other resources<a href="lesson-2a-simple-linear-regression.html#other-resources" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Some execellent resources to go deeper into linear regression:</p>
<ul>
<li><span class="citation">Kutner et al. (<a href="#ref-kutner-2005-applied" role="doc-biblioref">2005</a>)</span> for an excellent and comprehensive overview of linear regression.</li>
<li><span class="citation">Faraway (<a href="#ref-faraway-2016-linear" role="doc-biblioref">2016b</a>)</span> for a thorough discussion of linear regression in R.</li>
<li><span class="citation">Lipovetsky (<a href="#ref-lipovetsky2020statistical" role="doc-biblioref">2020</a>)</span> for a great introduction to linear regression for explanation rather than prediction.</li>
</ul>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-faraway-2016-linear" class="csl-entry">
———. 2016b. <em>Linear Models with r</em>. Chapman; Hall/CRC.
</div>
<div id="ref-kutner-2005-applied" class="csl-entry">
Kutner, M. H., C. J. Nachtsheim, J. Neter, and W. Li. 2005. <em>Applied Linear Statistical Models</em>. 5th ed. McGraw Hill.
</div>
<div id="ref-lipovetsky2020statistical" class="csl-entry">
Lipovetsky, Stan. 2020. Taylor &amp; Francis.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="overview-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lesson-2b-multiple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/bradleyboehmke/uc-bana-4080/edit/master/module-2/lesson-1.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
