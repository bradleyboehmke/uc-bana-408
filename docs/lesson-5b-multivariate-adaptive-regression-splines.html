<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>15 Lesson 5b: Multivariate Adaptive Regression Splines | Data Mining with R</title>
  <meta name="description" content="Master the art of data wrangling &amp; analysis with the R programming language." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="15 Lesson 5b: Multivariate Adaptive Regression Splines | Data Mining with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Master the art of data wrangling &amp; analysis with the R programming language." />
  <meta name="github-repo" content="bradleyboehmke/uc-bana-7025" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="15 Lesson 5b: Multivariate Adaptive Regression Splines | Data Mining with R" />
  <meta name="twitter:site" content="@bradleyboehmke" />
  <meta name="twitter:description" content="Master the art of data wrangling &amp; analysis with the R programming language." />
  

<meta name="author" content="Bradley Boehmke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lesson-5a-hyperparameter-tuning.html"/>
<link rel="next" href="overview-5.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.9/grViz.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">UC BANA 4080: Data Mining</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Syllabus</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-objectives"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#material"><i class="fa fa-check"></i>Material</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#class-structure"><i class="fa fa-check"></i>Class Structure</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#schedule"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#conventions-used-in-this-book"><i class="fa fa-check"></i>Conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#feedback"><i class="fa fa-check"></i>Feedback</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="part"><span><b>I Module 1</b></span></li>
<li class="chapter" data-level="1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1</b> Overview</a>
<ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html#learning-objectives-1"><i class="fa fa-check"></i><b>1.1</b> Learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="overview.html"><a href="overview.html#estimated-time-requirement"><i class="fa fa-check"></i><b>1.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="1.3" data-path="overview.html"><a href="overview.html#tasks"><i class="fa fa-check"></i><b>1.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html"><i class="fa fa-check"></i><b>2</b> Lesson 1a: Intro to machine learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#learning-objectives-2"><i class="fa fa-check"></i><b>2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>2.2</b> Supervised learning</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#regression-problems"><i class="fa fa-check"></i><b>2.2.1</b> Regression problems</a></li>
<li class="chapter" data-level="2.2.2" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#classification-problems"><i class="fa fa-check"></i><b>2.2.2</b> Classification problems</a></li>
<li class="chapter" data-level="2.2.3" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#knowledge-check"><i class="fa fa-check"></i><b>2.2.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.3</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#knowledge-check-1"><i class="fa fa-check"></i><b>2.3.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#machine-learning-in"><i class="fa fa-check"></i><b>2.4</b> Machine Learning in <svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#knowledge-check-2"><i class="fa fa-check"></i><b>2.4.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#the-data-sets"><i class="fa fa-check"></i><b>2.5</b> The data sets</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#boston-housing"><i class="fa fa-check"></i><b>2.5.1</b> Boston housing</a></li>
<li class="chapter" data-level="2.5.2" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#pima-indians-diabetes"><i class="fa fa-check"></i><b>2.5.2</b> Pima Indians Diabetes</a></li>
<li class="chapter" data-level="2.5.3" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#iris-flowers"><i class="fa fa-check"></i><b>2.5.3</b> Iris flowers</a></li>
<li class="chapter" data-level="2.5.4" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#ames-housing"><i class="fa fa-check"></i><b>2.5.4</b> Ames housing</a></li>
<li class="chapter" data-level="2.5.5" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#attrition"><i class="fa fa-check"></i><b>2.5.5</b> Attrition</a></li>
<li class="chapter" data-level="2.5.6" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#hitters"><i class="fa fa-check"></i><b>2.5.6</b> Hitters</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#what-youll-learn-next"><i class="fa fa-check"></i><b>2.6</b> What You’ll Learn Next</a></li>
<li class="chapter" data-level="2.7" data-path="lesson-1a-intro-to-machine-learning.html"><a href="lesson-1a-intro-to-machine-learning.html#exercises"><i class="fa fa-check"></i><b>2.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html"><i class="fa fa-check"></i><b>3</b> Lesson 1b: First model with Tidymodels</a>
<ul>
<li class="chapter" data-level="3.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#learning-objectives-3"><i class="fa fa-check"></i><b>3.1</b> Learning objectives</a></li>
<li class="chapter" data-level="3.2" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#prerequisites"><i class="fa fa-check"></i><b>3.2</b> Prerequisites</a></li>
<li class="chapter" data-level="3.3" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#data-splitting"><i class="fa fa-check"></i><b>3.3</b> Data splitting</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#simple-random-sampling"><i class="fa fa-check"></i><b>3.3.1</b> Simple random sampling</a></li>
<li class="chapter" data-level="3.3.2" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#stratified-sampling"><i class="fa fa-check"></i><b>3.3.2</b> Stratified sampling</a></li>
<li class="chapter" data-level="3.3.3" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#knowledge-check-3"><i class="fa fa-check"></i><b>3.3.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#building-models"><i class="fa fa-check"></i><b>3.4</b> Building models</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#knowledge-check-4"><i class="fa fa-check"></i><b>3.4.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#making-predictions"><i class="fa fa-check"></i><b>3.5</b> Making predictions</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#knowledge-check-5"><i class="fa fa-check"></i><b>3.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#evaluating-model-performance"><i class="fa fa-check"></i><b>3.6</b> Evaluating model performance</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#regression-models"><i class="fa fa-check"></i><b>3.6.1</b> Regression models</a></li>
<li class="chapter" data-level="3.6.2" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#classification-models"><i class="fa fa-check"></i><b>3.6.2</b> Classification models</a></li>
<li class="chapter" data-level="3.6.3" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#knowledge-check-6"><i class="fa fa-check"></i><b>3.6.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="lesson-1b-first-model-with-tidymodels.html"><a href="lesson-1b-first-model-with-tidymodels.html#exercises-1"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Module 2</b></span></li>
<li class="chapter" data-level="4" data-path="overview-1.html"><a href="overview-1.html"><i class="fa fa-check"></i><b>4</b> Overview</a>
<ul>
<li class="chapter" data-level="4.1" data-path="overview-1.html"><a href="overview-1.html#learning-objectives-4"><i class="fa fa-check"></i><b>4.1</b> Learning objectives</a></li>
<li class="chapter" data-level="4.2" data-path="overview-1.html"><a href="overview-1.html#estimated-time-requirement-1"><i class="fa fa-check"></i><b>4.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="4.3" data-path="overview-1.html"><a href="overview-1.html#tasks-1"><i class="fa fa-check"></i><b>4.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html"><i class="fa fa-check"></i><b>5</b> Lesson 2a: Simple linear regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#learning-objectives-5"><i class="fa fa-check"></i><b>5.1</b> Learning objectives</a></li>
<li class="chapter" data-level="5.2" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#prerequisites-1"><i class="fa fa-check"></i><b>5.2</b> Prerequisites</a></li>
<li class="chapter" data-level="5.3" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#correlation"><i class="fa fa-check"></i><b>5.3</b> Correlation</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#knowledge-check-7"><i class="fa fa-check"></i><b>5.3.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>5.4</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#best-fit-line"><i class="fa fa-check"></i><b>5.4.1</b> Best fit line</a></li>
<li class="chapter" data-level="5.4.2" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#estimating-best-fit"><i class="fa fa-check"></i><b>5.4.2</b> Estimating “best fit”</a></li>
<li class="chapter" data-level="5.4.3" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#inference"><i class="fa fa-check"></i><b>5.4.3</b> Inference</a></li>
<li class="chapter" data-level="5.4.4" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#knowledge-check-8"><i class="fa fa-check"></i><b>5.4.4</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#making-predictions-1"><i class="fa fa-check"></i><b>5.5</b> Making predictions</a></li>
<li class="chapter" data-level="5.6" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#assessing-model-accuracy"><i class="fa fa-check"></i><b>5.6</b> Assessing model accuracy</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#training-data-accuracy"><i class="fa fa-check"></i><b>5.6.1</b> Training data accuracy</a></li>
<li class="chapter" data-level="5.6.2" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#test-data-accuracy"><i class="fa fa-check"></i><b>5.6.2</b> Test data accuracy</a></li>
<li class="chapter" data-level="5.6.3" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#knowledge-check-9"><i class="fa fa-check"></i><b>5.6.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#exercises-2"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
<li class="chapter" data-level="5.8" data-path="lesson-2a-simple-linear-regression.html"><a href="lesson-2a-simple-linear-regression.html#other-resources"><i class="fa fa-check"></i><b>5.8</b> Other resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Lesson 2b: Multiple linear regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#learning-objectives-6"><i class="fa fa-check"></i><b>6.1</b> Learning objectives</a></li>
<li class="chapter" data-level="6.2" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#prerequisites-2"><i class="fa fa-check"></i><b>6.2</b> Prerequisites</a></li>
<li class="chapter" data-level="6.3" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#adding-additional-predictors"><i class="fa fa-check"></i><b>6.3</b> Adding additional predictors</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#knowledge-check-10"><i class="fa fa-check"></i><b>6.3.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#interactions"><i class="fa fa-check"></i><b>6.4</b> Interactions</a></li>
<li class="chapter" data-level="6.5" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#qualitative-predictors"><i class="fa fa-check"></i><b>6.5</b> Qualitative predictors</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#knowledge-check-11"><i class="fa fa-check"></i><b>6.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#including-many-predictors"><i class="fa fa-check"></i><b>6.6</b> Including many predictors</a></li>
<li class="chapter" data-level="6.7" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#feature-importance"><i class="fa fa-check"></i><b>6.7</b> Feature importance</a></li>
<li class="chapter" data-level="6.8" data-path="lesson-2b-multiple-linear-regression.html"><a href="lesson-2b-multiple-linear-regression.html#exercises-3"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>III Module 3</b></span></li>
<li class="chapter" data-level="7" data-path="overview-2.html"><a href="overview-2.html"><i class="fa fa-check"></i><b>7</b> Overview</a>
<ul>
<li class="chapter" data-level="7.1" data-path="overview-2.html"><a href="overview-2.html#learning-objectives-7"><i class="fa fa-check"></i><b>7.1</b> Learning objectives</a></li>
<li class="chapter" data-level="7.2" data-path="overview-2.html"><a href="overview-2.html#estimated-time-requirement-2"><i class="fa fa-check"></i><b>7.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="7.3" data-path="overview-2.html"><a href="overview-2.html#tasks-2"><i class="fa fa-check"></i><b>7.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html"><i class="fa fa-check"></i><b>8</b> Lesson 3a: Feature engineering</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#learning-objectives-8"><i class="fa fa-check"></i><b>8.1</b> Learning objectives</a></li>
<li class="chapter" data-level="8.2" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#prerequisites-3"><i class="fa fa-check"></i><b>8.2</b> Prerequisites</a></li>
<li class="chapter" data-level="8.3" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#create-a-recipe"><i class="fa fa-check"></i><b>8.3</b> Create a recipe</a></li>
<li class="chapter" data-level="8.4" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#numeric-features"><i class="fa fa-check"></i><b>8.4</b> Numeric features</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#standardizing"><i class="fa fa-check"></i><b>8.4.1</b> Standardizing</a></li>
<li class="chapter" data-level="8.4.2" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#normalizing"><i class="fa fa-check"></i><b>8.4.2</b> Normalizing</a></li>
<li class="chapter" data-level="8.4.3" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#knowledge-check-12"><i class="fa fa-check"></i><b>8.4.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#categorical-features"><i class="fa fa-check"></i><b>8.5</b> Categorical features</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#one-hot-dummy-encoding"><i class="fa fa-check"></i><b>8.5.1</b> One-hot &amp; dummy encoding</a></li>
<li class="chapter" data-level="8.5.2" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#ordinal-encoding"><i class="fa fa-check"></i><b>8.5.2</b> Ordinal encoding</a></li>
<li class="chapter" data-level="8.5.3" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#lumping"><i class="fa fa-check"></i><b>8.5.3</b> Lumping</a></li>
<li class="chapter" data-level="8.5.4" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#knowledge-check-13"><i class="fa fa-check"></i><b>8.5.4</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#fit-a-model-with-a-recipe"><i class="fa fa-check"></i><b>8.6</b> Fit a model with a recipe</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#knowledge-check-14"><i class="fa fa-check"></i><b>8.6.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="lesson-3a-feature-engineering.html"><a href="lesson-3a-feature-engineering.html#exercises-4"><i class="fa fa-check"></i><b>8.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html"><i class="fa fa-check"></i><b>9</b> Lesson 3b: Resampling</a>
<ul>
<li class="chapter" data-level="9.1" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#learning-objectives-9"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#prerequisites-4"><i class="fa fa-check"></i><b>9.2</b> Prerequisites</a></li>
<li class="chapter" data-level="9.3" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#resampling-cross-validation"><i class="fa fa-check"></i><b>9.3</b> Resampling &amp; cross-validation</a></li>
<li class="chapter" data-level="9.4" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>9.4</b> K-fold cross-validation</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#knowledge-check-15"><i class="fa fa-check"></i><b>9.4.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#bootstrap-resampling"><i class="fa fa-check"></i><b>9.5</b> Bootstrap resampling</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#knowledge-check-16"><i class="fa fa-check"></i><b>9.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#alternative-methods"><i class="fa fa-check"></i><b>9.6</b> Alternative methods</a></li>
<li class="chapter" data-level="9.7" data-path="lesson-3b-resampling.html"><a href="lesson-3b-resampling.html#exercises-5"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Module 4</b></span></li>
<li class="chapter" data-level="10" data-path="overview-3.html"><a href="overview-3.html"><i class="fa fa-check"></i><b>10</b> Overview</a>
<ul>
<li class="chapter" data-level="10.1" data-path="overview-3.html"><a href="overview-3.html#learning-objectives-10"><i class="fa fa-check"></i><b>10.1</b> Learning objectives</a></li>
<li class="chapter" data-level="10.2" data-path="overview-3.html"><a href="overview-3.html#estimated-time-requirement-3"><i class="fa fa-check"></i><b>10.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="10.3" data-path="overview-3.html"><a href="overview-3.html#tasks-3"><i class="fa fa-check"></i><b>10.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html"><i class="fa fa-check"></i><b>11</b> Lesson 4a: Logistic Regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#learning-objectives-11"><i class="fa fa-check"></i><b>11.1</b> Learning objectives</a></li>
<li class="chapter" data-level="11.2" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#prerequisites-5"><i class="fa fa-check"></i><b>11.2</b> Prerequisites</a></li>
<li class="chapter" data-level="11.3" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#why-logistic-regression"><i class="fa fa-check"></i><b>11.3</b> Why logistic regression</a></li>
<li class="chapter" data-level="11.4" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#simple-logistic-regression"><i class="fa fa-check"></i><b>11.4</b> Simple logistic regression</a></li>
<li class="chapter" data-level="11.5" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#interpretation"><i class="fa fa-check"></i><b>11.5</b> Interpretation</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-17"><i class="fa fa-check"></i><b>11.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>11.6</b> Multiple logistic regression</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-18"><i class="fa fa-check"></i><b>11.6.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#assessing-model-accuracy-1"><i class="fa fa-check"></i><b>11.7</b> Assessing model accuracy</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#accuracy"><i class="fa fa-check"></i><b>11.7.1</b> Accuracy</a></li>
<li class="chapter" data-level="11.7.2" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#confusion-matrix"><i class="fa fa-check"></i><b>11.7.2</b> Confusion matrix</a></li>
<li class="chapter" data-level="11.7.3" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#area-under-the-curve"><i class="fa fa-check"></i><b>11.7.3</b> Area under the curve</a></li>
<li class="chapter" data-level="11.7.4" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-19"><i class="fa fa-check"></i><b>11.7.4</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#cross-validation-performance"><i class="fa fa-check"></i><b>11.8</b> Cross-validation performance</a>
<ul>
<li class="chapter" data-level="11.8.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-20"><i class="fa fa-check"></i><b>11.8.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#feature-interpretation"><i class="fa fa-check"></i><b>11.9</b> Feature interpretation</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#knowledge-check-21"><i class="fa fa-check"></i><b>11.9.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#final-thoughts"><i class="fa fa-check"></i><b>11.10</b> Final thoughts</a></li>
<li class="chapter" data-level="11.11" data-path="lesson-4a-logistic-regression.html"><a href="lesson-4a-logistic-regression.html#exercises-6"><i class="fa fa-check"></i><b>11.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html"><i class="fa fa-check"></i><b>12</b> Lesson 4b: Regularized Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#learning-objectives-12"><i class="fa fa-check"></i><b>12.1</b> Learning objectives</a></li>
<li class="chapter" data-level="12.2" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#prerequisites-6"><i class="fa fa-check"></i><b>12.2</b> Prerequisites</a></li>
<li class="chapter" data-level="12.3" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#why-regularize"><i class="fa fa-check"></i><b>12.3</b> Why regularize?</a></li>
<li class="chapter" data-level="12.4" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#ridge-penalty"><i class="fa fa-check"></i><b>12.4</b> Ridge penalty</a></li>
<li class="chapter" data-level="12.5" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#lasso"><i class="fa fa-check"></i><b>12.5</b> Lasso penalty</a></li>
<li class="chapter" data-level="12.6" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#elastic"><i class="fa fa-check"></i><b>12.6</b> Elastic nets</a></li>
<li class="chapter" data-level="12.7" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#implementation"><i class="fa fa-check"></i><b>12.7</b> Implementation</a>
<ul>
<li class="chapter" data-level="12.7.1" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#knowledge-check-22"><i class="fa fa-check"></i><b>12.7.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#tuning-our-model"><i class="fa fa-check"></i><b>12.8</b> Tuning our model</a>
<ul>
<li class="chapter" data-level="12.8.1" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#tuning-regularization-strength"><i class="fa fa-check"></i><b>12.8.1</b> Tuning regularization strength</a></li>
<li class="chapter" data-level="12.8.2" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#tuning-regularization-type"><i class="fa fa-check"></i><b>12.8.2</b> Tuning regularization type</a></li>
<li class="chapter" data-level="12.8.3" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#tuning-regularization-type-strength"><i class="fa fa-check"></i><b>12.8.3</b> Tuning regularization type &amp; strength</a></li>
<li class="chapter" data-level="12.8.4" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#knowledge-check-23"><i class="fa fa-check"></i><b>12.8.4</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#feature-importance-1"><i class="fa fa-check"></i><b>12.9</b> Feature importance</a>
<ul>
<li class="chapter" data-level="12.9.1" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#knowledge-check-24"><i class="fa fa-check"></i><b>12.9.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="12.10" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#classification-problems-1"><i class="fa fa-check"></i><b>12.10</b> Classification problems</a></li>
<li class="chapter" data-level="12.11" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#final-thoughts-1"><i class="fa fa-check"></i><b>12.11</b> Final thoughts</a></li>
<li class="chapter" data-level="12.12" data-path="lesson-4b-regularized-regression.html"><a href="lesson-4b-regularized-regression.html#exercises-7"><i class="fa fa-check"></i><b>12.12</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Module 5</b></span></li>
<li class="chapter" data-level="13" data-path="overview-4.html"><a href="overview-4.html"><i class="fa fa-check"></i><b>13</b> Overview</a>
<ul>
<li class="chapter" data-level="13.1" data-path="overview-4.html"><a href="overview-4.html#learning-objectives-13"><i class="fa fa-check"></i><b>13.1</b> Learning objectives</a></li>
<li class="chapter" data-level="13.2" data-path="overview-4.html"><a href="overview-4.html#estimated-time-requirement-4"><i class="fa fa-check"></i><b>13.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="13.3" data-path="overview-4.html"><a href="overview-4.html#tasks-4"><i class="fa fa-check"></i><b>13.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html"><i class="fa fa-check"></i><b>14</b> Lesson 5a: Hyperparameter Tuning</a>
<ul>
<li class="chapter" data-level="14.1" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#learning-objectives-14"><i class="fa fa-check"></i><b>14.1</b> Learning objectives</a></li>
<li class="chapter" data-level="14.2" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#prerequisites-7"><i class="fa fa-check"></i><b>14.2</b> Prerequisites</a></li>
<li class="chapter" data-level="14.3" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>14.3</b> Bias-variance tradeoff</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#bias"><i class="fa fa-check"></i><b>14.3.1</b> Bias</a></li>
<li class="chapter" data-level="14.3.2" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#variance"><i class="fa fa-check"></i><b>14.3.2</b> Variance</a></li>
<li class="chapter" data-level="14.3.3" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#balancing-the-tradeoff"><i class="fa fa-check"></i><b>14.3.3</b> Balancing the tradeoff</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>14.4</b> Hyperparameter tuning</a></li>
<li class="chapter" data-level="14.5" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#implementation-1"><i class="fa fa-check"></i><b>14.5</b> Implementation</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#tuning"><i class="fa fa-check"></i><b>14.5.1</b> Tuning</a></li>
<li class="chapter" data-level="14.5.2" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#more-tuning"><i class="fa fa-check"></i><b>14.5.2</b> More tuning</a></li>
<li class="chapter" data-level="14.5.3" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#finalizing-our-model"><i class="fa fa-check"></i><b>14.5.3</b> Finalizing our model</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="lesson-5a-hyperparameter-tuning.html"><a href="lesson-5a-hyperparameter-tuning.html#exercises-8"><i class="fa fa-check"></i><b>14.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html"><i class="fa fa-check"></i><b>15</b> Lesson 5b: Multivariate Adaptive Regression Splines</a>
<ul>
<li class="chapter" data-level="15.1" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#learning-objectives-15"><i class="fa fa-check"></i><b>15.1</b> Learning objectives</a></li>
<li class="chapter" data-level="15.2" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#prerequisites-8"><i class="fa fa-check"></i><b>15.2</b> Prerequisites</a></li>
<li class="chapter" data-level="15.3" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#nonlinearity"><i class="fa fa-check"></i><b>15.3</b> Nonlinearity</a></li>
<li class="chapter" data-level="15.4" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#multivariate-adaptive-regression-splines"><i class="fa fa-check"></i><b>15.4</b> Multivariate adaptive regression splines</a></li>
<li class="chapter" data-level="15.5" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#fitting-a-mars-model"><i class="fa fa-check"></i><b>15.5</b> Fitting a MARS model</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#fitting-a-basic-model"><i class="fa fa-check"></i><b>15.5.1</b> Fitting a basic model</a></li>
<li class="chapter" data-level="15.5.2" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#fitting-a-full-model"><i class="fa fa-check"></i><b>15.5.2</b> Fitting a full model</a></li>
<li class="chapter" data-level="15.5.3" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#fitting-a-full-model-with-interactions"><i class="fa fa-check"></i><b>15.5.3</b> Fitting a full model with interactions</a></li>
<li class="chapter" data-level="15.5.4" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#knowledge-check-25"><i class="fa fa-check"></i><b>15.5.4</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#tuning-1"><i class="fa fa-check"></i><b>15.6</b> Tuning</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#knowledge-check-26"><i class="fa fa-check"></i><b>15.6.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#feature-interpretation-1"><i class="fa fa-check"></i><b>15.7</b> Feature interpretation</a></li>
<li class="chapter" data-level="15.8" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#final-thoughts-2"><i class="fa fa-check"></i><b>15.8</b> Final thoughts</a></li>
<li class="chapter" data-level="15.9" data-path="lesson-5b-multivariate-adaptive-regression-splines.html"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#exercises-9"><i class="fa fa-check"></i><b>15.9</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Module 6</b></span></li>
<li class="chapter" data-level="16" data-path="overview-5.html"><a href="overview-5.html"><i class="fa fa-check"></i><b>16</b> Overview</a>
<ul>
<li class="chapter" data-level="16.1" data-path="overview-5.html"><a href="overview-5.html#learning-objectives-16"><i class="fa fa-check"></i><b>16.1</b> Learning objectives</a></li>
<li class="chapter" data-level="16.2" data-path="overview-5.html"><a href="overview-5.html#estimated-time-requirement-5"><i class="fa fa-check"></i><b>16.2</b> Estimated time requirement</a></li>
<li class="chapter" data-level="16.3" data-path="overview-5.html"><a href="overview-5.html#tasks-5"><i class="fa fa-check"></i><b>16.3</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html"><i class="fa fa-check"></i><b>17</b> Lesson 6a: Decision Trees</a>
<ul>
<li class="chapter" data-level="17.1" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#learning-objectives-17"><i class="fa fa-check"></i><b>17.1</b> Learning objectives</a></li>
<li class="chapter" data-level="17.2" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#prerequisites-9"><i class="fa fa-check"></i><b>17.2</b> Prerequisites</a></li>
<li class="chapter" data-level="17.3" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#structure"><i class="fa fa-check"></i><b>17.3</b> Structure</a></li>
<li class="chapter" data-level="17.4" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#partitioning"><i class="fa fa-check"></i><b>17.4</b> Partitioning</a></li>
<li class="chapter" data-level="17.5" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#how-deep"><i class="fa fa-check"></i><b>17.5</b> How deep?</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#early-stopping"><i class="fa fa-check"></i><b>17.5.1</b> Early stopping</a></li>
<li class="chapter" data-level="17.5.2" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#pruning"><i class="fa fa-check"></i><b>17.5.2</b> Pruning</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#fitting-a-decision-tree"><i class="fa fa-check"></i><b>17.6</b> Fitting a decision tree</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#fitting-a-basic-model-1"><i class="fa fa-check"></i><b>17.6.1</b> Fitting a basic model</a></li>
<li class="chapter" data-level="17.6.2" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#fitting-a-full-model-1"><i class="fa fa-check"></i><b>17.6.2</b> Fitting a full model</a></li>
<li class="chapter" data-level="17.6.3" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#knowledge-check-27"><i class="fa fa-check"></i><b>17.6.3</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#tuning-2"><i class="fa fa-check"></i><b>17.7</b> Tuning</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#knowledge-check-28"><i class="fa fa-check"></i><b>17.7.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#feature-interpretation-2"><i class="fa fa-check"></i><b>17.8</b> Feature interpretation</a>
<ul>
<li class="chapter" data-level="17.8.1" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#knowledge-check-29"><i class="fa fa-check"></i><b>17.8.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="17.9" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#final-thoughts-3"><i class="fa fa-check"></i><b>17.9</b> Final thoughts</a></li>
<li class="chapter" data-level="17.10" data-path="lesson-6a-decision-trees.html"><a href="lesson-6a-decision-trees.html#exercises-10"><i class="fa fa-check"></i><b>17.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html"><i class="fa fa-check"></i><b>18</b> Lesson 6b: Bagging</a>
<ul>
<li class="chapter" data-level="18.1" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#learning-objectives-18"><i class="fa fa-check"></i><b>18.1</b> Learning objectives</a></li>
<li class="chapter" data-level="18.2" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#prerequisites-10"><i class="fa fa-check"></i><b>18.2</b> Prerequisites</a></li>
<li class="chapter" data-level="18.3" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#why-and-when-bagging-works"><i class="fa fa-check"></i><b>18.3</b> Why and when bagging works</a></li>
<li class="chapter" data-level="18.4" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#fitting-a-decision-tree-model"><i class="fa fa-check"></i><b>18.4</b> Fitting a decision tree model</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#knowledge-check-30"><i class="fa fa-check"></i><b>18.4.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#tuning-3"><i class="fa fa-check"></i><b>18.5</b> Tuning</a>
<ul>
<li class="chapter" data-level="18.5.1" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#knowledge-check-31"><i class="fa fa-check"></i><b>18.5.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#feature-interpretation-3"><i class="fa fa-check"></i><b>18.6</b> Feature interpretation</a>
<ul>
<li class="chapter" data-level="18.6.1" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#knowledge-check-32"><i class="fa fa-check"></i><b>18.6.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="18.7" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#final-thoughts-4"><i class="fa fa-check"></i><b>18.7</b> Final thoughts</a></li>
<li class="chapter" data-level="18.8" data-path="lesson-6b-bagging.html"><a href="lesson-6b-bagging.html#exercises-11"><i class="fa fa-check"></i><b>18.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html"><i class="fa fa-check"></i><b>19</b> Lesson 6c: Random Forests</a>
<ul>
<li class="chapter" data-level="19.1" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#learning-objectives-19"><i class="fa fa-check"></i><b>19.1</b> Learning objectives</a></li>
<li class="chapter" data-level="19.2" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#prerequisites-11"><i class="fa fa-check"></i><b>19.2</b> Prerequisites</a></li>
<li class="chapter" data-level="19.3" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#extending-bagging"><i class="fa fa-check"></i><b>19.3</b> Extending bagging</a></li>
<li class="chapter" data-level="19.4" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#out-of-the-box-performance"><i class="fa fa-check"></i><b>19.4</b> Out-of-the-box performance</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#knowledge-check-33"><i class="fa fa-check"></i><b>19.4.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#hyperparameters"><i class="fa fa-check"></i><b>19.5</b> Hyperparameters</a>
<ul>
<li class="chapter" data-level="19.5.1" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#number-of-trees"><i class="fa fa-check"></i><b>19.5.1</b> Number of trees</a></li>
<li class="chapter" data-level="19.5.2" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#mtry"><i class="fa fa-check"></i><b>19.5.2</b> <span class="math inline">\(m_{try}\)</span></a></li>
<li class="chapter" data-level="19.5.3" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#tree-complexity"><i class="fa fa-check"></i><b>19.5.3</b> Tree complexity</a></li>
<li class="chapter" data-level="19.5.4" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#others"><i class="fa fa-check"></i><b>19.5.4</b> Others</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#tuning-4"><i class="fa fa-check"></i><b>19.6</b> Tuning</a>
<ul>
<li class="chapter" data-level="19.6.1" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#knowledge-check-34"><i class="fa fa-check"></i><b>19.6.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="19.7" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#feature-interpretation-4"><i class="fa fa-check"></i><b>19.7</b> Feature interpretation</a>
<ul>
<li class="chapter" data-level="19.7.1" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#knowledge-check-35"><i class="fa fa-check"></i><b>19.7.1</b> Knowledge check</a></li>
</ul></li>
<li class="chapter" data-level="19.8" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#final-thoughts-5"><i class="fa fa-check"></i><b>19.8</b> Final thoughts</a></li>
<li class="chapter" data-level="19.9" data-path="lesson-6c-random-forests.html"><a href="lesson-6c-random-forests.html#exercises-12"><i class="fa fa-check"></i><b>19.9</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VII Additional Content</b></span></li>
<li class="chapter" data-level="" data-path="computing-environment.html"><a href="computing-environment.html"><i class="fa fa-check"></i>Computing Environment</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://www.uc.edu/" target="blank">University of Cincinnati</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Mining with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lesson-5b-multivariate-adaptive-regression-splines" class="section level1 hasAnchor" number="15">
<h1><span class="header-section-number">15</span> Lesson 5b: Multivariate Adaptive Regression Splines<a href="lesson-5b-multivariate-adaptive-regression-splines.html#lesson-5b-multivariate-adaptive-regression-splines" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The previous modules discussed algorithms that are intrinsically linear. Many of these models can be adapted to nonlinear patterns in the data by manually adding nonlinear model terms (e.g., squared terms, interaction effects, and other transformations of the original features); however, to do so you the analyst must know the specific nature of the nonlinearities and interactions <em>a priori</em>. Alternatively, there are numerous algorithms that are inherently nonlinear. When using these models, the exact form of the nonlinearity does not need to be known explicitly or specified prior to model training. Rather, these algorithms will search for, and discover, nonlinearities and interactions in the data that help maximize predictive accuracy.</p>
<p>This lesson discusses <em>multivariate adaptive regression splines</em> (MARS) <span class="citation">(<a href="#ref-friedman1991multivariate" role="doc-biblioref">J. H. Friedman 1991</a>)</span>, an algorithm that automatically creates a piecewise linear model which provides an intuitive stepping block into nonlinearity after grasping the concept of multiple linear regression. Future modules will focus on other nonlinear algorithms.</p>
<div id="learning-objectives-15" class="section level2 hasAnchor" number="15.1">
<h2><span class="header-section-number">15.1</span> Learning objectives<a href="lesson-5b-multivariate-adaptive-regression-splines.html#learning-objectives-15" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>By the end of this lesson you will know how:</p>
<ul>
<li>MARS models incorporates non-linear relationships with hinge functions (aka “knots”).</li>
<li>How to train and tune MARS models using the Tidymodels construct.</li>
<li>How to identify and visualize the most influential features in a MARS models.</li>
</ul>
</div>
<div id="prerequisites-8" class="section level2 hasAnchor" number="15.2">
<h2><span class="header-section-number">15.2</span> Prerequisites<a href="lesson-5b-multivariate-adaptive-regression-splines.html#prerequisites-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper packages</span></span>
<span id="cb149-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)   <span class="co"># for data wrangling &amp; plotting</span></span>
<span id="cb149-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Modeling packages</span></span>
<span id="cb149-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)  <span class="co"># for fitting MARS models</span></span>
<span id="cb149-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-7"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Model interpretability packages</span></span>
<span id="cb149-8"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vip)         <span class="co"># for variable importance</span></span>
<span id="cb149-9"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb149-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pdp)         <span class="co"># for variable relationships</span></span></code></pre></div>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Stratified sampling with the rsample package</span></span>
<span id="cb150-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb150-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb150-3" aria-hidden="true" tabindex="-1"></a>ames <span class="ot">&lt;-</span> AmesHousing<span class="sc">::</span><span class="fu">make_ames</span>()</span>
<span id="cb150-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb150-4" aria-hidden="true" tabindex="-1"></a>split  <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">initial_split</span>(ames, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> <span class="st">&quot;Sale_Price&quot;</span>)</span>
<span id="cb150-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb150-5" aria-hidden="true" tabindex="-1"></a>ames_train  <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">training</span>(split)</span>
<span id="cb150-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb150-6" aria-hidden="true" tabindex="-1"></a>ames_test   <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">testing</span>(split)</span></code></pre></div>
</div>
<div id="nonlinearity" class="section level2 hasAnchor" number="15.3">
<h2><span class="header-section-number">15.3</span> Nonlinearity<a href="lesson-5b-multivariate-adaptive-regression-splines.html#nonlinearity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_mcddkhi3&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_la01ilxg" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080 - Multivariate adaptive regression splines">
</iframe>
</div>
<p>In the previous modules, we focused on linear models (where the analyst has to explicitly specify any nonlinear relationships and interaction effects). We illustrated some of the advantages of linear models such as their ease and speed of computation and also the intuitive nature of interpreting their coefficients. However, linear models make a strong assumption about linearity, and this assumption is often a poor one, which can affect predictive accuracy.</p>
<p>We can extend linear models to capture any non-linear relationship. Typically, this is done by explicitly including polynomial terms (e.g., <span class="math inline">\(x_i^2\)</span>) or step functions. Polynomial regression is a form of regression in which the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is modeled as a <span class="math inline">\(d\)</span>th degree polynomial in <span class="math inline">\(X\)</span>. For example, the following equation represents a polynomial regression function where <span class="math inline">\(Y\)</span> is modeled as a <span class="math inline">\(d\)</span>-th degree polynomial in <span class="math inline">\(X\)</span>. Generally speaking, it is unusual to use <span class="math inline">\(d\)</span> greater than 3 or 4 as the larger <span class="math inline">\(d\)</span> becomes, the easier the function fit becomes overly flexible and oddly shaped…especially near the boundaries of the range of <span class="math inline">\(X\)</span> values. Increasing <span class="math inline">\(d\)</span> also tends to increase the presence of multicollinearity.</p>
<p><span class="math display">\[\begin{equation}
  y_i = \beta_0 + \beta_1 x_i + \beta_2 x^2_i + \beta_3 x^3_i \dots + \beta_d x^d_i + \epsilon_i,
\end{equation}\]</span></p>
<p>An alternative to polynomials is to use step functions. Whereas polynomial functions impose a global non-linear relationship, step functions break the range of <span class="math inline">\(X\)</span> into bins, and fit a simple constant (e.g., the mean response) in each. This amounts to converting a continuous feature into an ordered categorical variable such that our linear regression function is converted to the following equation</p>
<p><span class="math display">\[\begin{equation}
  y_i = \beta_0 + \beta_1 C_1(x_i) + \beta_2 C_2(x_i) + \beta_3 C_3(x_i) \dots + \beta_d C_d(x_i) + \epsilon_i,
\end{equation}\]</span></p>
<p>where <span class="math inline">\(C_1(x_i)\)</span> represents <span class="math inline">\(x_i\)</span> values ranging from <span class="math inline">\(c_1 \leq x_i &lt; c_2\)</span>, <span class="math inline">\(C_2\left(x_i\right)\)</span> represents <span class="math inline">\(x_i\)</span> values ranging from <span class="math inline">\(c_2 \leq x_i &lt; c_3\)</span>, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(C_d\left(x_i\right)\)</span> represents <span class="math inline">\(x_i\)</span> values ranging from <span class="math inline">\(c_{d-1} \leq x_i &lt; c_d\)</span>. The figure below contrasts linear, polynomial, and step function fits for non-linear, non-monotonic simulated data.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:nonlinear-comparisons"></span>
<img src="_main_files/figure-html/nonlinear-comparisons-1.png" alt="Blue line represents predicted (`y`) values as a function of `x` for alternative approaches to modeling explicit nonlinear regression patterns. (A) Traditional linear regression approach does not capture any nonlinearity unless the predictor or response is transformed (i.e. log transformation). (B) Degree-2 polynomial, (C) Degree-3 polynomial, (D) Step function cutting `x` into six categorical levels." width="768" />
<p class="caption">
Figure 15.1: Blue line represents predicted (<code>y</code>) values as a function of <code>x</code> for alternative approaches to modeling explicit nonlinear regression patterns. (A) Traditional linear regression approach does not capture any nonlinearity unless the predictor or response is transformed (i.e. log transformation). (B) Degree-2 polynomial, (C) Degree-3 polynomial, (D) Step function cutting <code>x</code> into six categorical levels.
</p>
</div>
<p>Although useful, the typical implementation of polynomial regression and step functions require the user to explicitly identify and incorporate which variables should have what specific degree of interaction or at what points of a variable <span class="math inline">\(X\)</span> should cut points be made for the step functions. Considering many data sets today can easily contain 50, 100, or more features, this would require an enormous and unnecessary time commitment from an analyst to determine these explicit non-linear settings.</p>
</div>
<div id="multivariate-adaptive-regression-splines" class="section level2 hasAnchor" number="15.4">
<h2><span class="header-section-number">15.4</span> Multivariate adaptive regression splines<a href="lesson-5b-multivariate-adaptive-regression-splines.html#multivariate-adaptive-regression-splines" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Multivariate adaptive regression splines (MARS) provide a convenient approach to capture the nonlinear relationships in the data by assessing cutpoints (<em>knots</em>) similar to step functions. The procedure assesses each data point for each predictor as a knot and creates a linear regression model with the candidate feature(s). For example, consider our non-linear, non-monotonic data above where <span class="math inline">\(Y = f\left(X\right)\)</span>. The MARS procedure will first look for the single point across the range of <code>X</code> values where two different linear relationships between <code>Y</code> and <code>X</code> achieve the smallest error (e.g., smallest SSE). What results is known as a hinge function <span class="math inline">\(h\left(x-a\right)\)</span>, where <span class="math inline">\(a\)</span> is the cutpoint value. For a single knot (Figure (A)), our hinge function is <span class="math inline">\(h\left(\text{x}-1.183606\right)\)</span> such that our two linear models for <code>Y</code> are</p>
<p><span class="math display">\[\begin{equation}
  \text{y} =
  \begin{cases}
    \beta_0 + \beta_1(1.183606 - \text{x}) &amp; \text{x} &lt; 1.183606, \\
    \beta_0 + \beta_1(\text{x} - 1.183606) &amp; \text{x} &gt; 1.183606
  \end{cases}
\end{equation}\]</span></p>
<p>Once the first knot has been found, the search continues for a second knot which is found at <span class="math inline">\(x = 4.898114\)</span> (plot B in figure below). This results in three linear models for <code>y</code>:</p>
<p><span class="math display">\[\begin{equation}
  \text{y} =
  \begin{cases}
    \beta_0 + \beta_1(1.183606 - \text{x}) &amp; \text{x} &lt; 1.183606, \\
    \beta_0 + \beta_1(\text{x} - 1.183606) &amp; \text{x} &gt; 1.183606 \quad \&amp; \quad \text{x} &lt; 4.898114, \\
    \beta_0 + \beta_1(4.898114 - \text{x}) &amp; \text{x} &gt; 4.898114
  \end{cases}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:examples-of-multiple-knots"></span>
<img src="_main_files/figure-html/examples-of-multiple-knots-1.png" alt="Examples of fitted regression splines of one (A), two (B), three (C), and four (D) knots." width="768" />
<p class="caption">
Figure 15.2: Examples of fitted regression splines of one (A), two (B), three (C), and four (D) knots.
</p>
</div>
<p>This procedure continues until many knots are found, producing a (potentially) highly non-linear prediction equation. Although including many knots may allow us to fit a really good relationship with our training data, it may not generalize very well to new, unseen data. Consequently, once the full set of knots has been identified, we can sequentially remove knots that do not contribute significantly to predictive accuracy. This process is known as “pruning” and we can use cross-validation, as we have with the previous models, to find the optimal number of knots.</p>
</div>
<div id="fitting-a-mars-model" class="section level2 hasAnchor" number="15.5">
<h2><span class="header-section-number">15.5</span> Fitting a MARS model<a href="lesson-5b-multivariate-adaptive-regression-splines.html#fitting-a-mars-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_kcg69q6j&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_6igoesxe" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080 - Fitting MARS models">
</iframe>
</div>
<div id="fitting-a-basic-model" class="section level3 hasAnchor" number="15.5.1">
<h3><span class="header-section-number">15.5.1</span> Fitting a basic model<a href="lesson-5b-multivariate-adaptive-regression-splines.html#fitting-a-basic-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ll start by fitting a basic model using <code>Gr_Liv_Area</code> and <code>Year_Built</code> to predict our <code>Sales_Price</code>. In both R, the modeling algorithm will assess all potential knots across all supplied features and then will prune to the optimal number of knots based on an expected change in <span class="math inline">\(R^2\)</span> (for the training data) of less than 0.001. This calculation is performed by the Generalized cross-validation (GCV) procedure, which is a computational shortcut for linear models that produces an approximate leave-one-out cross-validation error metric <span class="citation">(<a href="#ref-golub1979generalized" role="doc-biblioref">Golub, Heath, and Wahba 1979</a>)</span>.</p>
<div class="note">
<p>
Note that MARS models do not require normalization or standardization
of numeric features.
</p>
</div>
<p>In R, we use the <code>parsnip::mars()</code> function which provides a default setting of using the <code>earth</code> package, which is the most popular package for MARS functionality in R.</p>
<div class="warning">
<p>
When you run the below code you may get an error that states:
<code>This engine requires some package installs: ‘earth’</code>. This
is because the engine that Tidymodels uses is the earth package. If you
get this error then install the earth package with
<code>install.packages(“earth”)</code> and rerun the code.
</p>
</div>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-1" aria-hidden="true" tabindex="-1"></a>mars_fit <span class="ot">&lt;-</span> <span class="fu">mars</span>(<span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb151-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Sale_Price <span class="sc">~</span> Gr_Liv_Area <span class="sc">+</span> Year_Built, ames_train)</span>
<span id="cb151-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb151-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-4" aria-hidden="true" tabindex="-1"></a>mars_fit</span>
<span id="cb151-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-5" aria-hidden="true" tabindex="-1"></a><span class="do">## parsnip model object</span></span>
<span id="cb151-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-6" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb151-7"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Selected 9 of 10 terms, and 2 of 2 predictors</span></span>
<span id="cb151-8"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Termination condition: RSq changed by less than 0.001 at 10 terms</span></span>
<span id="cb151-9"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Importance: Gr_Liv_Area, Year_Built</span></span>
<span id="cb151-10"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terms at each degree of interaction: 1 8 (additive model)</span></span>
<span id="cb151-11"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb151-11" aria-hidden="true" tabindex="-1"></a><span class="do">## GCV 1802525892    RSS 3.632344e+12    GRSq 0.7208907    RSq 0.7252347</span></span></code></pre></div>
<p>In the results above, the GCV is reported along with other metrics (<span class="math inline">\(R^2\)</span>, residual sum of squares - RSS). We can use this info to compute the RMSE, which is in the low to mid $40K range. Keep in mind that this RMSE is not a cross-validated RMSE, just the RMSE on the training data (we’ll do some cross-validation shortly).</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE</span></span>
<span id="cb152-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb152-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(mars_fit<span class="sc">$</span>fit<span class="sc">$</span>rss <span class="sc">/</span> <span class="fu">nrow</span>(ames_train))</span>
<span id="cb152-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb152-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 42103.92</span></span></code></pre></div>
<p>Looking at the coefficients below, you’ll notice that we see a knot in <code>Gr_Liv_Area</code> at 3395. This suggests that as homes exceed 3395 square feet there is a change in the linear relationship between <code>Gr_Liv_Area</code> and <code>Sale_Price</code> compared to homes that are less than 3395 square feet. In fact, we can see multiple knots across the range of <code>Gr_Liv_Area</code> and <code>Year_Built</code>. Our model has taken two features (<code>Gr_Liv_Area</code> and <code>Year_Built</code>) and split them into 8 features by creating knots along these feature values.</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="co"># coefficients</span></span>
<span id="cb153-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-2" aria-hidden="true" tabindex="-1"></a>mars_fit<span class="sc">$</span>fit<span class="sc">$</span>coefficients</span>
<span id="cb153-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-3" aria-hidden="true" tabindex="-1"></a><span class="do">##                       Sale_Price</span></span>
<span id="cb153-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-4" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)         295628.31484</span></span>
<span id="cb153-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-5" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Gr_Liv_Area-3395)   -772.99460</span></span>
<span id="cb153-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-6" aria-hidden="true" tabindex="-1"></a><span class="do">## h(3395-Gr_Liv_Area)    -61.66360</span></span>
<span id="cb153-7"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-7" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2002-Year_Built)    -685.97770</span></span>
<span id="cb153-8"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-8" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Gr_Liv_Area-2169)     27.57111</span></span>
<span id="cb153-9"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-9" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Gr_Liv_Area-3194)    516.04236</span></span>
<span id="cb153-10"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-10" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Gr_Liv_Area-1456)     41.77324</span></span>
<span id="cb153-11"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-11" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Year_Built-1977)     910.94873</span></span>
<span id="cb153-12"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb153-12" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Year_Built-2004)   12519.67884</span></span></code></pre></div>
<div class="tip">
<p>
The most important tuning parameter in a MARS model is the number of
knots to use for a given feature. However, this is automatically baked
into the algorithm so we get this tuning for free!
</p>
</div>
</div>
<div id="fitting-a-full-model" class="section level3 hasAnchor" number="15.5.2">
<h3><span class="header-section-number">15.5.2</span> Fitting a full model<a href="lesson-5b-multivariate-adaptive-regression-splines.html#fitting-a-full-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Next, lets go ahead and fit a full model to include all Ames housing features. As you’ll see in the results we experience significant improvement in the training RMSE (low $20K). However, recall that this is not a cross-validated RMSE, but rather the RMSE for the training data in which the model was fit. Consequently, this is likely an overfit model but we’ll perform a cross-validation approach in the next section to get a more accurate generalized RMSE.</p>
<p>MARS models are no different then other algorithms where we need to convert categorical features to numeric values. In R, the MARS modeling engine “earth” will automatically one-hot encode all categorical features. This leads to over 300 features in our dataset; however, when you look at the results you will see that only a fraction of these features are used in the trained model (note it says “29 of 308 predictors”). However, there will actually be more coefficients then the features used because of the knots. For example of the 29 features, 41 coefficients are developed since many of these features are used multiple times (i.e. <code>h(Gr_Liv_Area-3194)</code>, <code>h(3194-Gr_Liv_Area)</code>).</p>
<div class="note">
<p>
We call this process of feature elimination and knot refinement as
“pruning the knots”.
</p>
</div>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-1" aria-hidden="true" tabindex="-1"></a>mars_fit <span class="ot">&lt;-</span> <span class="fu">mars</span>(<span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb154-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Sale_Price <span class="sc">~</span> ., ames_train)</span>
<span id="cb154-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-4" aria-hidden="true" tabindex="-1"></a>mars_fit</span>
<span id="cb154-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-5" aria-hidden="true" tabindex="-1"></a><span class="do">## parsnip model object</span></span>
<span id="cb154-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-6" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb154-7"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Selected 41 of 45 terms, and 29 of 308 predictors</span></span>
<span id="cb154-8"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Termination condition: RSq changed by less than 0.001 at 45 terms</span></span>
<span id="cb154-9"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Importance: Gr_Liv_Area, Year_Built, Total_Bsmt_SF, ...</span></span>
<span id="cb154-10"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terms at each degree of interaction: 1 40 (additive model)</span></span>
<span id="cb154-11"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-11" aria-hidden="true" tabindex="-1"></a><span class="do">## GCV 511589986    RSS 967008439675    GRSq 0.9207836    RSq 0.9268516</span></span>
<span id="cb154-12"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-13"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-13" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE</span></span>
<span id="cb154-14"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-14" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(mars_fit<span class="sc">$</span>fit<span class="sc">$</span>rss <span class="sc">/</span> <span class="fu">nrow</span>(ames_train))</span>
<span id="cb154-15"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-15" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 21724.22</span></span>
<span id="cb154-16"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-17"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-17" aria-hidden="true" tabindex="-1"></a><span class="co"># coefficients</span></span>
<span id="cb154-18"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-18" aria-hidden="true" tabindex="-1"></a>mars_fit<span class="sc">$</span>fit<span class="sc">$</span>coefficients</span>
<span id="cb154-19"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-19" aria-hidden="true" tabindex="-1"></a><span class="do">##                                   Sale_Price</span></span>
<span id="cb154-20"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-20" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)                     2.275972e+05</span></span>
<span id="cb154-21"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-21" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Gr_Liv_Area-3194)            -2.879934e+02</span></span>
<span id="cb154-22"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-22" aria-hidden="true" tabindex="-1"></a><span class="do">## h(3194-Gr_Liv_Area)            -5.861227e+01</span></span>
<span id="cb154-23"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-23" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Year_Built-2002)              3.128137e+03</span></span>
<span id="cb154-24"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-24" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2002-Year_Built)             -4.506370e+02</span></span>
<span id="cb154-25"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-25" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Total_Bsmt_SF-2223)          -6.531310e+02</span></span>
<span id="cb154-26"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-26" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2223-Total_Bsmt_SF)          -2.903002e+01</span></span>
<span id="cb154-27"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-27" aria-hidden="true" tabindex="-1"></a><span class="do">## h(1656-Bsmt_Unf_SF)             2.152273e+01</span></span>
<span id="cb154-28"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualVery_Excellent      1.198770e+05</span></span>
<span id="cb154-29"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualExcellent           7.325741e+04</span></span>
<span id="cb154-30"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualVery_Good           3.065703e+04</span></span>
<span id="cb154-31"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-31" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2-Kitchen_AbvGr)              2.199288e+04</span></span>
<span id="cb154-32"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-32" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Second_Flr_SF-1427)           3.071810e+02</span></span>
<span id="cb154-33"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-33" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Year_Remod_Add-1973)          3.198457e+02</span></span>
<span id="cb154-34"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-34" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Lot_Area-6720)                4.956740e-01</span></span>
<span id="cb154-35"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-35" aria-hidden="true" tabindex="-1"></a><span class="do">## h(6720-Lot_Area)               -3.972312e+00</span></span>
<span id="cb154-36"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-36" aria-hidden="true" tabindex="-1"></a><span class="do">## FunctionalTyp                   1.642861e+04</span></span>
<span id="cb154-37"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-37" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Bedroom_AbvGr-4)             -1.304304e+04</span></span>
<span id="cb154-38"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-38" aria-hidden="true" tabindex="-1"></a><span class="do">## h(4-Bedroom_AbvGr)              3.044473e+03</span></span>
<span id="cb154-39"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-39" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Garage_Cars-2)                1.351805e+04</span></span>
<span id="cb154-40"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-40" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2-Garage_Cars)               -5.099554e+03</span></span>
<span id="cb154-41"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-41" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Total_Bsmt_SF-2136)           5.756167e+02</span></span>
<span id="cb154-42"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-42" aria-hidden="true" tabindex="-1"></a><span class="do">## NeighborhoodCrawford            2.015380e+04</span></span>
<span id="cb154-43"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-43" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualGood                1.167108e+04</span></span>
<span id="cb154-44"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-44" aria-hidden="true" tabindex="-1"></a><span class="do">## Condition_2PosN                -1.164630e+05</span></span>
<span id="cb154-45"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-45" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_CondGood                3.000370e+04</span></span>
<span id="cb154-46"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-46" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_CondVery_Good           3.380410e+04</span></span>
<span id="cb154-47"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-47" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_CondAbove_Average       2.231569e+04</span></span>
<span id="cb154-48"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-48" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Gr_Liv_Area-2898)             1.591394e+02</span></span>
<span id="cb154-49"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-49" aria-hidden="true" tabindex="-1"></a><span class="do">## NeighborhoodGreen_Hills         9.830591e+04</span></span>
<span id="cb154-50"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-50" aria-hidden="true" tabindex="-1"></a><span class="do">## Roof_MatlWdShngl                6.744107e+04</span></span>
<span id="cb154-51"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-51" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Longitude--93.6572)          -1.229288e+05</span></span>
<span id="cb154-52"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-52" aria-hidden="true" tabindex="-1"></a><span class="do">## h(-93.6572-Longitude)          -1.570905e+05</span></span>
<span id="cb154-53"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-53" aria-hidden="true" tabindex="-1"></a><span class="do">## NeighborhoodStone_Brook         3.162134e+04</span></span>
<span id="cb154-54"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-54" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_CondExcellent           3.886202e+04</span></span>
<span id="cb154-55"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-55" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_CondAverage             1.480704e+04</span></span>
<span id="cb154-56"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-56" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Total_Bsmt_SF-1295)           3.234334e+01</span></span>
<span id="cb154-57"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-57" aria-hidden="true" tabindex="-1"></a><span class="do">## NeighborhoodNorthridge          2.693805e+04</span></span>
<span id="cb154-58"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-58" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Fireplaces-1)                 6.808179e+03</span></span>
<span id="cb154-59"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-59" aria-hidden="true" tabindex="-1"></a><span class="do">## h(1-Fireplaces)                -4.374554e+03</span></span>
<span id="cb154-60"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb154-60" aria-hidden="true" tabindex="-1"></a><span class="do">## NeighborhoodNorthridge_Heights  1.455416e+04</span></span></code></pre></div>
</div>
<div id="fitting-a-full-model-with-interactions" class="section level3 hasAnchor" number="15.5.3">
<h3><span class="header-section-number">15.5.3</span> Fitting a full model with interactions<a href="lesson-5b-multivariate-adaptive-regression-splines.html#fitting-a-full-model-with-interactions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In addition to pruning the number of knots, MARS models allow us to also assess potential interactions between different hinge functions. The following example illustrates by allowing second degree interactions. You can see that now our model includes interaction terms between a maximum of two hinge functions (e.g. in the results you see <code>h(Year_Built-2002)*h(Gr_Liv_Area-2398)</code> which represents an interaction effect for those houses built after 2002 and have more than 2,398 square feet of living space).</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-1" aria-hidden="true" tabindex="-1"></a>mars_fit <span class="ot">&lt;-</span> <span class="fu">mars</span>(<span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>, <span class="at">prod_degree =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb155-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Sale_Price <span class="sc">~</span> ., ames_train)</span>
<span id="cb155-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-4" aria-hidden="true" tabindex="-1"></a>mars_fit</span>
<span id="cb155-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-5" aria-hidden="true" tabindex="-1"></a><span class="do">## parsnip model object</span></span>
<span id="cb155-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-6" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb155-7"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Selected 45 of 50 terms, and 27 of 308 predictors</span></span>
<span id="cb155-8"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Termination condition: RSq changed by less than 0.001 at 50 terms</span></span>
<span id="cb155-9"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Importance: Gr_Liv_Area, Year_Built, Total_Bsmt_SF, ...</span></span>
<span id="cb155-10"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terms at each degree of interaction: 1 20 24</span></span>
<span id="cb155-11"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-11" aria-hidden="true" tabindex="-1"></a><span class="do">## GCV 420267019    RSS 7.70355e+11    GRSq 0.9349244    RSq 0.9417272</span></span>
<span id="cb155-12"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-13"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-13" aria-hidden="true" tabindex="-1"></a><span class="co"># coefficients</span></span>
<span id="cb155-14"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-14" aria-hidden="true" tabindex="-1"></a>mars_fit<span class="sc">$</span>fit<span class="sc">$</span>coefficients</span>
<span id="cb155-15"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-15" aria-hidden="true" tabindex="-1"></a><span class="do">##                                                    Sale_Price</span></span>
<span id="cb155-16"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-16" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)                                      3.473694e+05</span></span>
<span id="cb155-17"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-17" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Gr_Liv_Area-3194)                              2.302940e+02</span></span>
<span id="cb155-18"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-18" aria-hidden="true" tabindex="-1"></a><span class="do">## h(3194-Gr_Liv_Area)                             -7.005261e+01</span></span>
<span id="cb155-19"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-19" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Year_Built-2002)                               5.242461e+03</span></span>
<span id="cb155-20"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-20" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2002-Year_Built)                              -7.360079e+02</span></span>
<span id="cb155-21"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-21" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Total_Bsmt_SF-2223)                            1.181093e+02</span></span>
<span id="cb155-22"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-22" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2223-Total_Bsmt_SF)                           -4.901140e+01</span></span>
<span id="cb155-23"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-23" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Year_Built-2002)*h(Gr_Liv_Area-2398)           9.035037e+00</span></span>
<span id="cb155-24"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-24" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Year_Built-2002)*h(2398-Gr_Liv_Area)          -3.382639e+00</span></span>
<span id="cb155-25"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-25" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Bsmt_Unf_SF-625)*h(3194-Gr_Liv_Area)          -1.145129e-02</span></span>
<span id="cb155-26"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-26" aria-hidden="true" tabindex="-1"></a><span class="do">## h(625-Bsmt_Unf_SF)*h(3194-Gr_Liv_Area)           9.905591e-03</span></span>
<span id="cb155-27"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-27" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2002-Year_Built)*h(Total_Bsmt_SF-912)         -7.674355e-01</span></span>
<span id="cb155-28"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-28" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2002-Year_Built)*h(912-Total_Bsmt_SF)          2.277350e-01</span></span>
<span id="cb155-29"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Mas_Vnr_TypeStone*h(Gr_Liv_Area-3194)           -5.876451e+02</span></span>
<span id="cb155-30"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-30" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Bedroom_AbvGr-4)                              -9.649772e+03</span></span>
<span id="cb155-31"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-31" aria-hidden="true" tabindex="-1"></a><span class="do">## h(4-Bedroom_AbvGr)                               5.208836e+03</span></span>
<span id="cb155-32"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-32" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualVery_Excellent                       1.095179e+05</span></span>
<span id="cb155-33"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-33" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualExcellent                           -1.578730e+05</span></span>
<span id="cb155-34"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-34" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualVery_Good                            3.794092e+04</span></span>
<span id="cb155-35"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-35" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Lot_Area-6720)                                 3.325029e+00</span></span>
<span id="cb155-36"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-36" aria-hidden="true" tabindex="-1"></a><span class="do">## h(6720-Lot_Area)                                -4.188039e+00</span></span>
<span id="cb155-37"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-37" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2002-Year_Built)*h(Year_Remod_Add-1971)        7.085099e+00</span></span>
<span id="cb155-38"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-38" aria-hidden="true" tabindex="-1"></a><span class="do">## NeighborhoodCrawford*h(2002-Year_Built)          3.213659e+02</span></span>
<span id="cb155-39"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-39" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Lot_Area-6720)*h(Garage_Cars-3)               -1.943527e+00</span></span>
<span id="cb155-40"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-40" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Lot_Area-6720)*h(3-Garage_Cars)               -1.237131e+00</span></span>
<span id="cb155-41"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-41" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualExcellent*FoundationPConc            2.295300e+05</span></span>
<span id="cb155-42"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-42" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualGood                                 1.940091e+04</span></span>
<span id="cb155-43"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-43" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_QualAbove_Average*h(2223-Total_Bsmt_SF)  6.438535e+00</span></span>
<span id="cb155-44"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-44" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2002-Year_Built)*Sale_ConditionNormal          2.183528e+02</span></span>
<span id="cb155-45"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-45" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Lot_Area-6720)*h(144-Screen_Porch)            -1.051737e-02</span></span>
<span id="cb155-46"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-46" aria-hidden="true" tabindex="-1"></a><span class="do">## FunctionalTyp                                    1.481969e+04</span></span>
<span id="cb155-47"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-47" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Kitchen_AbvGr-1)                              -1.802740e+04</span></span>
<span id="cb155-48"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-48" aria-hidden="true" tabindex="-1"></a><span class="do">## h(First_Flr_SF-2444)                            -7.656120e+01</span></span>
<span id="cb155-49"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-49" aria-hidden="true" tabindex="-1"></a><span class="do">## h(2444-First_Flr_SF)                            -7.045054e+00</span></span>
<span id="cb155-50"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-50" aria-hidden="true" tabindex="-1"></a><span class="do">## NeighborhoodStone_Brook*h(Year_Built-2002)       1.033983e+04</span></span>
<span id="cb155-51"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-51" aria-hidden="true" tabindex="-1"></a><span class="do">## Overall_CondGood*h(2002-Year_Built)              1.598754e+02</span></span>
<span id="cb155-52"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-52" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Longitude--93.6563)                           -9.367281e+05</span></span>
<span id="cb155-53"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-53" aria-hidden="true" tabindex="-1"></a><span class="do">## h(-93.6563-Longitude)                           -9.165180e+05</span></span>
<span id="cb155-54"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-54" aria-hidden="true" tabindex="-1"></a><span class="do">## h(3194-Gr_Liv_Area)*h(Longitude--93.6559)        4.432167e+02</span></span>
<span id="cb155-55"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-55" aria-hidden="true" tabindex="-1"></a><span class="do">## h(3194-Gr_Liv_Area)*h(-93.6559-Longitude)        3.803470e+02</span></span>
<span id="cb155-56"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-56" aria-hidden="true" tabindex="-1"></a><span class="do">## FunctionalTyp*h(Garage_Area-542)                 3.500866e+01</span></span>
<span id="cb155-57"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-57" aria-hidden="true" tabindex="-1"></a><span class="do">## NeighborhoodGreen_Hills*FunctionalTyp            9.112140e+04</span></span>
<span id="cb155-58"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-58" aria-hidden="true" tabindex="-1"></a><span class="do">## h(4-Bedroom_AbvGr)*h(Fireplaces-1)               5.820943e+03</span></span>
<span id="cb155-59"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-59" aria-hidden="true" tabindex="-1"></a><span class="do">## h(4-Bedroom_AbvGr)*h(1-Fireplaces)              -2.482522e+03</span></span>
<span id="cb155-60"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb155-60" aria-hidden="true" tabindex="-1"></a><span class="do">## h(Bsmt_Unf_SF-1237)*h(4-Bedroom_AbvGr)          -3.737860e+01</span></span></code></pre></div>
</div>
<div id="knowledge-check-25" class="section level3 hasAnchor" number="15.5.4">
<h3><span class="header-section-number">15.5.4</span> Knowledge check<a href="lesson-5b-multivariate-adaptive-regression-splines.html#knowledge-check-25" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="todo">
<p>
Using the <code>boston.csv</code> dataset:
</p>
<ol style="list-style-type: decimal">
<li>
Apply a MARS model where <code>cmedv</code> is the response variable
and <code>rm</code> and <code>lstat</code> are the two predictor
variables.
<ul>
<li>
What is the training data RSS for the final model?
</li>
<li>
Assess the coefficients. How many hinges/knots are there? Can you
interpret the coefficients?
</li>
</ul>
</li>
<li>
Apply a MARS model that uses all possible predictor variables.
<ul>
<li>
What is the training data RSS for the final model?
</li>
<li>
Assess the coefficients. How many hinges/knots are there? Can you
interpret the coefficients?
</li>
</ul>
</li>
<li>
Apply a MARS model that uses all possible predictor variables and
allows for two-way interactions.
<ul>
<li>
What is the training data RSS for the final model?
</li>
<li>
Assess the coefficients. How many hinges/knots are there? Can you
interpret the coefficients?
</li>
</ul>
</li>
</ol>
</div>
</div>
</div>
<div id="tuning-1" class="section level2 hasAnchor" number="15.6">
<h2><span class="header-section-number">15.6</span> Tuning<a href="lesson-5b-multivariate-adaptive-regression-splines.html#tuning-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="video">
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1492301/sp/149230100/embedIframeJs/uiconf_id/49148882/partner_id/1492301?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_mgupbbkl&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en_US&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_mtruyjr6" width="640" height="610" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="BANA 4080 - Tuning MARS models">
</iframe>
</div>
<p>There are two important tuning parameters associated with MARS models: the maximum degree of interactions and the number of terms retained in the final model. We need to perform a grid search to identify the optimal combination of these hyperparameters that minimize prediction error (the above pruning process was based only on an approximation of CV model performance on the training data rather than an exact <em>k</em>-fold CV process). As in the previous lesson, we’ll perform a CV grid search to identify the optimal hyperparameter mix. Below, we set up a grid that assesses different combinations of interaction complexity and the number of terms to retain in the final model.</p>
<div class="warning">
<p>
Rarely is there any benefit in assessing greater than 3-rd degree
interactions. Also, realize that tuning MARS models can become
computationally intense. Its often beneficial to start with 10 evenly
spaced values for the maximum terms and then you can always zoom in to a
region once you find an approximate optimal solution.
</p>
</div>
<p>In R, our hyperparameters are <code>num_terms</code> (number of terms retained in the model) and <code>prod_degrees</code> (maximum degree of interaction allowed). Note that in R we can use <code>num_terms()</code> and <code>prod_degree()</code> from the dials package to create a tuning grid. By default <code>prod_degree()</code> will use values of 1 and 2 (no interactions and 2 degree interactions).</p>
<p>Our results show that our top 5 performing models all include 2 degree interactions and between 37-49 total terms (“knots”).</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create MARS model object</span></span>
<span id="cb156-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-2" aria-hidden="true" tabindex="-1"></a>mars_mod <span class="ot">&lt;-</span> <span class="fu">mars</span>(<span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>, <span class="at">num_terms =</span> <span class="fu">tune</span>(), <span class="at">prod_degree =</span> <span class="fu">tune</span>())</span>
<span id="cb156-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-4" aria-hidden="true" tabindex="-1"></a><span class="co"># create k-fold cross validation object</span></span>
<span id="cb156-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb156-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-6" aria-hidden="true" tabindex="-1"></a>folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(ames_train, <span class="at">v =</span> <span class="dv">5</span>)</span>
<span id="cb156-7"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-8"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-8" aria-hidden="true" tabindex="-1"></a><span class="co"># create our model recipe</span></span>
<span id="cb156-9"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-9" aria-hidden="true" tabindex="-1"></a>model_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Sale_Price <span class="sc">~</span> ., <span class="at">data =</span> ames_train)</span>
<span id="cb156-10"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-11"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-11" aria-hidden="true" tabindex="-1"></a><span class="co"># create a hyper parameter tuning grid</span></span>
<span id="cb156-12"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-12" aria-hidden="true" tabindex="-1"></a>hyper_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(</span>
<span id="cb156-13"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-13" aria-hidden="true" tabindex="-1"></a> <span class="fu">num_terms</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">100</span>)), </span>
<span id="cb156-14"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-14" aria-hidden="true" tabindex="-1"></a> <span class="fu">prod_degree</span>(),</span>
<span id="cb156-15"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-15" aria-hidden="true" tabindex="-1"></a> <span class="at">levels =</span> <span class="dv">50</span></span>
<span id="cb156-16"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-16" aria-hidden="true" tabindex="-1"></a> )</span>
<span id="cb156-17"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-18"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-18" aria-hidden="true" tabindex="-1"></a><span class="co"># train our model across the hyper parameter grid</span></span>
<span id="cb156-19"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-19" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(mars_mod, model_recipe, <span class="at">resamples =</span> folds, <span class="at">grid =</span> hyper_grid)</span>
<span id="cb156-20"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-21"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-21" aria-hidden="true" tabindex="-1"></a><span class="co"># get best results</span></span>
<span id="cb156-22"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-22" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(results, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span>
<span id="cb156-23"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-23" aria-hidden="true" tabindex="-1"></a><span class="do">## # A tibble: 5 × 8</span></span>
<span id="cb156-24"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-24" aria-hidden="true" tabindex="-1"></a><span class="do">##   num_terms prod_de…¹ .metric .esti…²   mean     n std_err .config</span></span>
<span id="cb156-25"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-25" aria-hidden="true" tabindex="-1"></a><span class="do">##       &lt;int&gt;     &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  </span></span>
<span id="cb156-26"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-26" aria-hidden="true" tabindex="-1"></a><span class="do">## 1        37         2 rmse    standa… 26546.     5   2969. Prepro…</span></span>
<span id="cb156-27"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-27" aria-hidden="true" tabindex="-1"></a><span class="do">## 2        43         2 rmse    standa… 26701.     5   2617. Prepro…</span></span>
<span id="cb156-28"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-28" aria-hidden="true" tabindex="-1"></a><span class="do">## 3        45         2 rmse    standa… 26702.     5   2618. Prepro…</span></span>
<span id="cb156-29"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-29" aria-hidden="true" tabindex="-1"></a><span class="do">## 4        47         2 rmse    standa… 26702.     5   2618. Prepro…</span></span>
<span id="cb156-30"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-30" aria-hidden="true" tabindex="-1"></a><span class="do">## 5        49         2 rmse    standa… 26702.     5   2618. Prepro…</span></span>
<span id="cb156-31"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb156-31" aria-hidden="true" tabindex="-1"></a><span class="do">## # … with abbreviated variable names ¹​prod_degree, ²​.estimator</span></span></code></pre></div>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(results)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-275-1.png" width="576" style="display: block; margin: auto;" /></p>
<div id="knowledge-check-26" class="section level3 hasAnchor" number="15.6.1">
<h3><span class="header-section-number">15.6.1</span> Knowledge check<a href="lesson-5b-multivariate-adaptive-regression-splines.html#knowledge-check-26" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="todo">
<p>
Using the <code>boston.csv</code> dataset apply a MARS model that
uses all possible predictor variables and tune for the number of terms
and interactions.
</p>
<ul>
<li>
Use a 5-fold cross validation procedure to tune your model.
</li>
<li>
For number of terms used (<code>num_terms</code>) assess values
between 1-50.
</li>
<li>
For possible interaction degrees use the default
<code>prod_degree()</code>.
</li>
<li>
Assess a total of 10 values from each parameter
(<code>levels = 10</code>).
</li>
</ul>
<p>
Which model(s) provide the lowest cross validated RMSE? What
hyperparameter values provide these optimal results?
</p>
</div>
</div>
</div>
<div id="feature-interpretation-1" class="section level2 hasAnchor" number="15.7">
<h2><span class="header-section-number">15.7</span> Feature interpretation<a href="lesson-5b-multivariate-adaptive-regression-splines.html#feature-interpretation-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>MARS models use a backwards elimination feature selection routine that looks at reductions in the GCV estimate of error as each predictor is added to the model. This total reduction can be used as the variable importance measure (<code>"gcv"</code>). Since MARS will automatically include and exclude terms during the pruning process, it essentially performs automated feature selection. If a predictor was never used in any of the MARS basis functions in the final model (after pruning), it has an importance value of zero. Alternatively, you can also monitor the change in the residual sums of squares (RSS) as terms are added (<code>"rss"</code>); however, you will often see very little difference between these methods. The following examples extract the feature importance values based on RSS.</p>
<p>The below shows that our most influential feature <code>Gr_Liv_Area</code> followed by <code>Year_Built</code>, <code>Total_Bsmt_SF</code>, <code>Overall_QualExcellent</code>, etc.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-1" aria-hidden="true" tabindex="-1"></a>best_hyperparameters <span class="ot">&lt;-</span> <span class="fu">select_best</span>(results, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span>
<span id="cb158-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb158-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-3" aria-hidden="true" tabindex="-1"></a>final_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb158-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">add_model</span>(mars_mod) <span class="sc">%&gt;%</span></span>
<span id="cb158-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">add_formula</span>(Sale_Price <span class="sc">~</span> .) <span class="sc">%&gt;%</span></span>
<span id="cb158-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">finalize_workflow</span>(best_hyperparameters)</span>
<span id="cb158-7"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb158-8"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-8" aria-hidden="true" tabindex="-1"></a><span class="co"># plot top 20 influential variables</span></span>
<span id="cb158-9"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-9" aria-hidden="true" tabindex="-1"></a>final_wf <span class="sc">%&gt;%</span></span>
<span id="cb158-10"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-10" aria-hidden="true" tabindex="-1"></a>   <span class="fu">fit</span>(<span class="at">data =</span> ames_train) <span class="sc">%&gt;%</span> </span>
<span id="cb158-11"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-11" aria-hidden="true" tabindex="-1"></a>   <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span></span>
<span id="cb158-12"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb158-12" aria-hidden="true" tabindex="-1"></a>   <span class="fu">vip</span>(<span class="dv">20</span>, <span class="at">type =</span> <span class="st">&quot;rss&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-277-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Since our relationship between our response variable and the predictor variables are now non-linear, it becomes helpful to visualize the relationship between the most influential feature(s) and the response variable to see how they relate. We can do that with <strong><em>partial dependence plots</em></strong> (PDPs). PDPs plot the change in the average predicted value of our model (<span class="math inline">\(\hat y\)</span>) as specified feature(s) vary over their marginal distribution.</p>
<p>We can then use the <a href="https://bgreenwell.github.io/pdp/index.html"><code>pdp</code></a> package to extract the partial dependence values in order to plot the relationship between predicted <code>Sale_Price</code> and <code>Gr_Liv_Area</code>. Don’t get too hung up in the code here. But you can see that based on our PDP, as homes exceed 3,200ish square feet we see a steepening increase in the relationship.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prediction function</span></span>
<span id="cb159-2"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-2" aria-hidden="true" tabindex="-1"></a>pdp_pred_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(object, newdata) {</span>
<span id="cb159-3"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(<span class="fu">predict</span>(object, newdata, <span class="at">type =</span> <span class="st">&quot;numeric&quot;</span>)<span class="sc">$</span>.pred)</span>
<span id="cb159-4"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb159-5"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb159-6"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-6" aria-hidden="true" tabindex="-1"></a><span class="co"># use the pdp package to extract partial dependence predictions</span></span>
<span id="cb159-7"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-7" aria-hidden="true" tabindex="-1"></a><span class="co"># and then plot</span></span>
<span id="cb159-8"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-8" aria-hidden="true" tabindex="-1"></a>final_wf <span class="sc">%&gt;%</span></span>
<span id="cb159-9"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-9" aria-hidden="true" tabindex="-1"></a>   <span class="fu">fit</span>(<span class="at">data =</span> ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb159-10"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-10" aria-hidden="true" tabindex="-1"></a>  pdp<span class="sc">::</span><span class="fu">partial</span>(</span>
<span id="cb159-11"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-11" aria-hidden="true" tabindex="-1"></a>   <span class="at">pred.var =</span> <span class="st">&quot;Gr_Liv_Area&quot;</span>, </span>
<span id="cb159-12"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-12" aria-hidden="true" tabindex="-1"></a>   <span class="at">pred.fun =</span> pdp_pred_fun,</span>
<span id="cb159-13"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-13" aria-hidden="true" tabindex="-1"></a>   <span class="at">grid.resolution =</span> <span class="dv">10</span>, </span>
<span id="cb159-14"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-14" aria-hidden="true" tabindex="-1"></a>   <span class="at">train =</span> ames_train</span>
<span id="cb159-15"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb159-16"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(Gr_Liv_Area, yhat)) <span class="sc">+</span></span>
<span id="cb159-17"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb159-18"><a href="lesson-5b-multivariate-adaptive-regression-splines.html#cb159-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>dollar)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-278-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="final-thoughts-2" class="section level2 hasAnchor" number="15.8">
<h2><span class="header-section-number">15.8</span> Final thoughts<a href="lesson-5b-multivariate-adaptive-regression-splines.html#final-thoughts-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are several advantages to MARS. First, MARS naturally handles mixed types of predictors (quantitative and qualitative). MARS considers all possible binary partitions of the categories for a qualitative predictor into two groups.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> Each group then generates a pair of piecewise indicator functions for the two categories. MARS also requires minimal feature engineering (e.g., feature scaling) and performs automated feature selection. For example, since MARS scans each predictor to identify a split that improves predictive accuracy, non-informative features will not be chosen. Furthermore, highly correlated predictors do not impede predictive accuracy as much as they do with OLS models.</p>
<p>However, one disadvantage to MARS models is that they’re typically slower to train. Since the algorithm scans each value of each predictor for potential cutpoints, computational performance can suffer as both <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span> increase. Also, although correlated predictors do not necessarily impede model performance, they can make model interpretation difficult. When two features are nearly perfectly correlated, the algorithm will essentially select the first one it happens to come across when scanning the features. Then, since it randomly selected one, the correlated feature will likely not be included as it adds no additional explanatory power.</p>
</div>
<div id="exercises-9" class="section level2 hasAnchor" number="15.9">
<h2><span class="header-section-number">15.9</span> Exercises<a href="lesson-5b-multivariate-adaptive-regression-splines.html#exercises-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="todo">
<p>
Using the same <code>kernlab::spam</code> data we saw in the <a
href="https://bradleyboehmke.github.io/uc-bana-4080/lesson-4b-regularized-regression.html#classification-problems-1">section
12.10</a>…
</p>
<ol style="list-style-type: decimal">
<li>
Split the data into 70-30 training-test sets.
</li>
<li>
Apply a MARS classification model where <code>type</code> is our
response variable and use all possible predictor variables.
<ul>
<li>
Use a 5-fold cross-validation procedure.
</li>
<li>
Tune number of terms used (<code>num_terms</code>) with values
ranging 1-100.
</li>
<li>
Tune number of interaction degrees with the default
<code>prod_degree()</code> values.
</li>
<li>
Assess a total of 50 values from each parameter
(<code>levels = 50</code>).
</li>
</ul>
</li>
<li>
Which model(s) have the highest AUC (<code>roc_auc</code>)
scores?
</li>
<li>
What hyperparameter values provide these optimal results?
</li>
<li>
Use the hyperparameter values that provide the best results to
finalize your workflow and and identify the top 20 most influential
predictors.
</li>
<li>
<strong>Bonus</strong>: See if you can create a PDP plot for the #1
most influential variable. What does the relationship between this
feature and the response variable look like?
</li>
</ol>
</div>

</div>
</div>



<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-friedman1991multivariate" class="csl-entry">
Friedman, Jerome H. 1991. <span>“Multivariate Adaptive Regression Splines.”</span> <em>The Annals of Statistics</em>, 1–67.
</div>
<div id="ref-golub1979generalized" class="csl-entry">
Golub, Gene H, Michael Heath, and Grace Wahba. 1979. <span>“Generalized Cross-Validation as a Method for Choosing a Good Ridge Parameter.”</span> <em>Technometrics</em> 21 (2): 215–23.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>This is very similar to CART-like decision trees which you’ll be exposed to in a later module.<a href="lesson-5b-multivariate-adaptive-regression-splines.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lesson-5a-hyperparameter-tuning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="overview-5.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/bradleyboehmke/uc-bana-4080/edit/master/module-5/lesson-2.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
